{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа № 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM, Flatten\n",
    "from keras.layers import SimpleRNN, Reshape\n",
    "from keras.layers import GRU, Embedding\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем текст с http://lib.ru. Сохраним в директорию на ПК."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/hui/Desktop/mprinc.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем текст для дальнейшей работы с ним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 77626 characters\n"
     ]
    }
   ],
   "source": [
    "with open(path, 'r') as f:\n",
    "    text = f.read().lower()\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на первые 250 символов текста в качестве дополнительной проверки и визуализации, что все считано верно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u0014антуан де сент-экзюпери. маленький принц\u0015\n",
      "\n",
      " леону верту\n",
      "\n",
      " прошу детей простить меня за то, что я посвятил эту книжку взрослому. скажу в оправдание: этот взрослый - мой самый лучший друг. и еще: он понимает все на свете, даже детские книжки. и, нако\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь уникальных символов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем набор всех символов в тексте и составляем 2 словаря:\n",
    "char_indices содержит символы и соответствующий им индекс\n",
    "indices_char позволит по индексу получить символ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: ['\\n', '\\x14', '\\x15', ' ', '!', '\"', '(', ')', ',', '-', '.', '0', '1', '2', '3', '5', '6', '7', '8', '9', ':', ';', '?', 'i', 'n', 'v', 'x', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я']\n",
      "total chars: 59\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', chars)\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательная функция, выдающая случайный индекс символа из наиболее вероятных.\n",
    "temperature отвечает за вариативность выдаваемых индексов: более низкое значение будет выдавать более вероятный символ с меньшей вариативностью, и наоборот.\n",
    "На вход функции подаются вероятности, предсказанные сетью, на выходе выдается индекс символа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature = 1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разрезаем текст на куски по maxlen символов с шагом step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 25862\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем полученные последовательности символов в последовательности векторов, в которых каждому символу будет соотвествовать вектор [x1, x2, ..., xK, ... xN], где xK = 1, если K равно индексу данного символа, N = количество в нашем наборе chars, а все остальные значения равны нулю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем гиперпараметры:\n",
    "* `batch_size`: размер мини-батча, чем он меньше, тем менее усредненной будет ошибка, соответственно, будет выше точность и меньше вероятность скатиться в локальный минимум;\n",
    "* `gen_length`: длина генерируемого текста в символах;\n",
    "* `options`: массив опций для обучения; в нем хранятся наборы параметров для определенной архитектуры;\n",
    "* `size`: количество узлов в слое;\n",
    "* `epochs`: количество эпох (итераций) обучения;\n",
    "* `type_of_network`: используемая нейросетевая архитектура;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "# Длина словаря символов\n",
    "vocab_size = len(chars)\n",
    "\n",
    "gen_length = 1500\n",
    "\n",
    "options = [\n",
    "\n",
    "    {\n",
    "        'size': 128,\n",
    "        'epochs': 120,\n",
    "        'type_of_network': '1RNN'\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        'size': 128,\n",
    "        'epochs': 120,\n",
    "        'type_of_network': '1LSTM'\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        'size': 256,\n",
    "        'epochs': 30,\n",
    "        'type_of_network': '2LSTM'\n",
    "    }, \n",
    "    \n",
    "    {\n",
    "        'size': 256,\n",
    "        'epochs': 25,\n",
    "        'type_of_network': '1GRU'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "Для каждого набора параметров строим модель, обучаем ее за `epochs` итераций.\n",
    "Первой моделью будет обычная полносвязная RNN нейросеть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обнуляем сессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "option = options[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для построения необходимой модели в зависимости от нужного типа.\n",
    "\n",
    "- Архитектура сети RNN в виде последовательности слоёв. Определяем один скрытый слой LSTM с option['size'] = 256 единицами памяти. Для регуляции сети будем использовать слой Dropout с вероятностью 20, как правило, это делает узлы более устойчивыми к входам. Выходной уровень - это полносвязный (Dense) уровень, использующий функцию активации softmax для вывода прогнозирования вероятности для каждого из 51 символов в диапазоне от 0 до 1.\n",
    "\n",
    "- Архитектуру однослойной LSTM в виде последовательности слоёв. Определяем один скрытый слой LSTM с option['size'] = 128 единицами памяти. Для регуляции сети будем использовать слой Dropout с вероятностью 20, как правило, это делает узлы более устойчивыми к входам. Выходной уровень - это полносвязный (Dense) уровень, использующий функцию активации softmax для вывода прогнозирования вероятности для каждого из 51 символов в диапазоне от 0 до 1.\n",
    "\n",
    "- Архитектуру двухслойной LSTM сети в виде последовательности слоёв. Определим количество узлов для слоя LSTM, равное 256, и добавим еще второй слой LSTM. Теперь мы имеем уже два слоя LSTM, регулязацию которых выполняем при помощи техники dropout. Добавляем полносвязный слой с функцией активации - непрерывная функция softmax с 51 выходами, равное количеству уникальных символов в нашем тексте.\n",
    "\n",
    "- Архитектура ондослойной GRU сети: количество узлов равно 256 для слоя GRU. Добавим слой Flatten для изменения формы тензора. Во избежание переобучения добавим Dropout. Затем добавляем полносвязный слой с функцией активации - непрерывная функция softmax с 51 выходами, равное количеству уникальных символов в нашем тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def building_model(vocab_size, batch_size, maxlen):\n",
    "    model = Sequential()\n",
    "    if option['type_of_network'] == '1RNN':\n",
    "        model.add(SimpleRNN(option['size'], input_shape = (maxlen, vocab_size)))\n",
    "        model.add(Dense(vocab_size)) \n",
    "        model.add(Activation('softmax'))\n",
    "    elif option['type_of_network'] == '1LSTM':\n",
    "        model.add(LSTM(option['size'], input_shape = (maxlen, vocab_size)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(vocab_size))\n",
    "        model.add(Activation('softmax'))\n",
    "    elif option['type_of_network'] == '2LSTM':\n",
    "        model.add(LSTM(option['size'], input_shape = (maxlen, vocab_size), return_sequences = True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(option['size']))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(vocab_size))\n",
    "        model.add(Activation('softmax'))\n",
    "    else:\n",
    "        model4.add(GRU(option['size'], input_shape = (maxlen, vocab_size), return_sequences = True))\n",
    "        model4.add(Flatten())\n",
    "        model4.add(Dense(vocab_size)) \n",
    "        model4.add(Activation('softmax')) \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим первую модель (обычная полносвязная RNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 128)               24064     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 59)                7611      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 59)                0         \n",
      "=================================================================\n",
      "Total params: 31,675\n",
      "Trainable params: 31,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = building_model(vocab_size = vocab_size, batch_size = batch_size, maxlen = maxlen)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настроим модель с потерями и метриками с помощью model.compile(). В качестве функции оптимизации используем Adam.\n",
    "Дальше определяем функцию потери (то есть измеряем, насколько мы ошиблись) с помощью categorical crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во время обучения нейросети будем записывать полученные лучшие веса в директорию checkpoint_dir. Самые лучшие веса позже понадобятся для генерации текста по уже обученной нейросети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'C:/Users/hui/Desktop/AI/training_checkpoints_2/'\n",
    "filepath = \"C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-{epoch:02d}-with-{loss:.4f}.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вызов ModelCheckpoint - это колбек (callback) (функция обратного вызова), которая выполняет сохранение контрольных точек в течение и в конце тренировки. Таким способом можно использовать тренированную модель без необходимости тренировать ее вновь, или начинать тренировку с того места, где она была остановлена в случае если тренировочный процесс был прерван."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренируем нашу модель на количестве эпох = 120 и размером батча = 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "25862/25862 [==============================] - 7s 284us/step - loss: 2.3866\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.38664, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-01-with-2.3866.hdf5\n",
      "Epoch 2/120\n",
      "25862/25862 [==============================] - 8s 296us/step - loss: 2.3234\n",
      "\n",
      "Epoch 00002: loss improved from 2.38664 to 2.32338, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-02-with-2.3234.hdf5\n",
      "Epoch 3/120\n",
      "25862/25862 [==============================] - 8s 297us/step - loss: 2.2690\n",
      "\n",
      "Epoch 00003: loss improved from 2.32338 to 2.26904, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-03-with-2.2690.hdf5\n",
      "Epoch 4/120\n",
      "25862/25862 [==============================] - 8s 315us/step - loss: 2.2318\n",
      "\n",
      "Epoch 00004: loss improved from 2.26904 to 2.23184, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-04-with-2.2318.hdf5\n",
      "Epoch 5/120\n",
      "25862/25862 [==============================] - 7s 287us/step - loss: 2.1936\n",
      "\n",
      "Epoch 00005: loss improved from 2.23184 to 2.19364, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-05-with-2.1936.hdf5\n",
      "Epoch 6/120\n",
      "25862/25862 [==============================] - 7s 285us/step - loss: 2.1639\n",
      "\n",
      "Epoch 00006: loss improved from 2.19364 to 2.16391, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-06-with-2.1639.hdf5\n",
      "Epoch 7/120\n",
      "25862/25862 [==============================] - 6s 240us/step - loss: 2.1393\n",
      "\n",
      "Epoch 00007: loss improved from 2.16391 to 2.13928, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-07-with-2.1393.hdf5\n",
      "Epoch 8/120\n",
      "25862/25862 [==============================] - 6s 235us/step - loss: 2.1195\n",
      "\n",
      "Epoch 00008: loss improved from 2.13928 to 2.11953, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-08-with-2.1195.hdf5\n",
      "Epoch 9/120\n",
      "25862/25862 [==============================] - 6s 233us/step - loss: 2.0890\n",
      "\n",
      "Epoch 00009: loss improved from 2.11953 to 2.08903, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-09-with-2.0890.hdf5\n",
      "Epoch 10/120\n",
      "25862/25862 [==============================] - 6s 243us/step - loss: 2.0745\n",
      "\n",
      "Epoch 00010: loss improved from 2.08903 to 2.07450, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-10-with-2.0745.hdf5\n",
      "Epoch 11/120\n",
      "25862/25862 [==============================] - 6s 231us/step - loss: 2.0458\n",
      "\n",
      "Epoch 00011: loss improved from 2.07450 to 2.04582, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-11-with-2.0458.hdf5\n",
      "Epoch 12/120\n",
      "25862/25862 [==============================] - 6s 230us/step - loss: 2.0305\n",
      "\n",
      "Epoch 00012: loss improved from 2.04582 to 2.03045, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-12-with-2.0305.hdf5\n",
      "Epoch 13/120\n",
      "25862/25862 [==============================] - 6s 249us/step - loss: 2.0019\n",
      "\n",
      "Epoch 00013: loss improved from 2.03045 to 2.00187, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-13-with-2.0019.hdf5\n",
      "Epoch 14/120\n",
      "25862/25862 [==============================] - 6s 233us/step - loss: 1.9935\n",
      "\n",
      "Epoch 00014: loss improved from 2.00187 to 1.99346, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-14-with-1.9935.hdf5\n",
      "Epoch 15/120\n",
      "25862/25862 [==============================] - 6s 237us/step - loss: 1.9704\n",
      "\n",
      "Epoch 00015: loss improved from 1.99346 to 1.97037, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-15-with-1.9704.hdf5\n",
      "Epoch 16/120\n",
      "25862/25862 [==============================] - 6s 231us/step - loss: 1.9594\n",
      "\n",
      "Epoch 00016: loss improved from 1.97037 to 1.95939, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-16-with-1.9594.hdf5\n",
      "Epoch 17/120\n",
      "25862/25862 [==============================] - 6s 232us/step - loss: 1.9361\n",
      "\n",
      "Epoch 00017: loss improved from 1.95939 to 1.93607, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-17-with-1.9361.hdf5\n",
      "Epoch 18/120\n",
      "25862/25862 [==============================] - 6s 236us/step - loss: 1.9186\n",
      "\n",
      "Epoch 00018: loss improved from 1.93607 to 1.91859, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-18-with-1.9186.hdf5\n",
      "Epoch 19/120\n",
      "25862/25862 [==============================] - 6s 238us/step - loss: 1.9093\n",
      "\n",
      "Epoch 00019: loss improved from 1.91859 to 1.90930, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-19-with-1.9093.hdf5\n",
      "Epoch 20/120\n",
      "25862/25862 [==============================] - 6s 238us/step - loss: 1.8850\n",
      "\n",
      "Epoch 00020: loss improved from 1.90930 to 1.88502, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-20-with-1.8850.hdf5\n",
      "Epoch 21/120\n",
      "25862/25862 [==============================] - 6s 234us/step - loss: 1.8656\n",
      "\n",
      "Epoch 00021: loss improved from 1.88502 to 1.86558, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-21-with-1.8656.hdf5\n",
      "Epoch 22/120\n",
      "25862/25862 [==============================] - 6s 230us/step - loss: 1.8694\n",
      "\n",
      "Epoch 00022: loss did not improve from 1.86558\n",
      "Epoch 23/120\n",
      "25862/25862 [==============================] - 6s 230us/step - loss: 1.8370\n",
      "\n",
      "Epoch 00023: loss improved from 1.86558 to 1.83697, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-23-with-1.8370.hdf5\n",
      "Epoch 24/120\n",
      "25862/25862 [==============================] - 6s 231us/step - loss: 1.8197\n",
      "\n",
      "Epoch 00024: loss improved from 1.83697 to 1.81970, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-24-with-1.8197.hdf5\n",
      "Epoch 25/120\n",
      "25862/25862 [==============================] - 6s 227us/step - loss: 1.8124\n",
      "\n",
      "Epoch 00025: loss improved from 1.81970 to 1.81242, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-25-with-1.8124.hdf5\n",
      "Epoch 26/120\n",
      "25862/25862 [==============================] - 6s 235us/step - loss: 1.7931\n",
      "\n",
      "Epoch 00026: loss improved from 1.81242 to 1.79309, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-26-with-1.7931.hdf5\n",
      "Epoch 27/120\n",
      "25862/25862 [==============================] - 6s 232us/step - loss: 1.7762\n",
      "\n",
      "Epoch 00027: loss improved from 1.79309 to 1.77618, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-27-with-1.7762.hdf5\n",
      "Epoch 28/120\n",
      "25862/25862 [==============================] - 6s 235us/step - loss: 1.7771\n",
      "\n",
      "Epoch 00028: loss did not improve from 1.77618\n",
      "Epoch 29/120\n",
      "25862/25862 [==============================] - 6s 230us/step - loss: 1.7644\n",
      "\n",
      "Epoch 00029: loss improved from 1.77618 to 1.76445, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-29-with-1.7644.hdf5\n",
      "Epoch 30/120\n",
      "25862/25862 [==============================] - 6s 236us/step - loss: 1.7359\n",
      "\n",
      "Epoch 00030: loss improved from 1.76445 to 1.73589, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-30-with-1.7359.hdf5\n",
      "Epoch 31/120\n",
      "25862/25862 [==============================] - 6s 244us/step - loss: 1.7125\n",
      "\n",
      "Epoch 00031: loss improved from 1.73589 to 1.71251, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-31-with-1.7125.hdf5\n",
      "Epoch 32/120\n",
      "25862/25862 [==============================] - 6s 230us/step - loss: 1.7114\n",
      "\n",
      "Epoch 00032: loss improved from 1.71251 to 1.71140, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-32-with-1.7114.hdf5\n",
      "Epoch 33/120\n",
      "25862/25862 [==============================] - 6s 236us/step - loss: 1.7117\n",
      "\n",
      "Epoch 00033: loss did not improve from 1.71140\n",
      "Epoch 34/120\n",
      "25862/25862 [==============================] - 6s 232us/step - loss: 1.6777\n",
      "\n",
      "Epoch 00034: loss improved from 1.71140 to 1.67771, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-34-with-1.6777.hdf5\n",
      "Epoch 35/120\n",
      "25862/25862 [==============================] - 6s 233us/step - loss: 1.6705\n",
      "\n",
      "Epoch 00035: loss improved from 1.67771 to 1.67048, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-35-with-1.6705.hdf5\n",
      "Epoch 36/120\n",
      "25862/25862 [==============================] - 6s 235us/step - loss: 1.6564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00036: loss improved from 1.67048 to 1.65641, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-36-with-1.6564.hdf5\n",
      "Epoch 37/120\n",
      "25862/25862 [==============================] - 6s 226us/step - loss: 1.6382\n",
      "\n",
      "Epoch 00037: loss improved from 1.65641 to 1.63820, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-37-with-1.6382.hdf5\n",
      "Epoch 38/120\n",
      "25862/25862 [==============================] - 6s 229us/step - loss: 1.6159\n",
      "\n",
      "Epoch 00038: loss improved from 1.63820 to 1.61593, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-38-with-1.6159.hdf5\n",
      "Epoch 39/120\n",
      "25862/25862 [==============================] - 6s 230us/step - loss: 1.6086\n",
      "\n",
      "Epoch 00039: loss improved from 1.61593 to 1.60862, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-39-with-1.6086.hdf5\n",
      "Epoch 40/120\n",
      "25862/25862 [==============================] - 6s 228us/step - loss: 1.6143\n",
      "\n",
      "Epoch 00040: loss did not improve from 1.60862\n",
      "Epoch 41/120\n",
      "25862/25862 [==============================] - 6s 223us/step - loss: 1.6025\n",
      "\n",
      "Epoch 00041: loss improved from 1.60862 to 1.60250, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-41-with-1.6025.hdf5\n",
      "Epoch 42/120\n",
      "25862/25862 [==============================] - 6s 228us/step - loss: 1.5845\n",
      "\n",
      "Epoch 00042: loss improved from 1.60250 to 1.58451, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-42-with-1.5845.hdf5\n",
      "Epoch 43/120\n",
      "25862/25862 [==============================] - 6s 230us/step - loss: 1.5862\n",
      "\n",
      "Epoch 00043: loss did not improve from 1.58451\n",
      "Epoch 44/120\n",
      "25862/25862 [==============================] - 6s 225us/step - loss: 1.5378\n",
      "\n",
      "Epoch 00044: loss improved from 1.58451 to 1.53779, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-44-with-1.5378.hdf5\n",
      "Epoch 45/120\n",
      "25862/25862 [==============================] - 6s 227us/step - loss: 1.5473\n",
      "\n",
      "Epoch 00045: loss did not improve from 1.53779\n",
      "Epoch 46/120\n",
      "25862/25862 [==============================] - 7s 273us/step - loss: 1.5610\n",
      "\n",
      "Epoch 00046: loss did not improve from 1.53779\n",
      "Epoch 47/120\n",
      "25862/25862 [==============================] - 6s 234us/step - loss: 1.5218\n",
      "\n",
      "Epoch 00047: loss improved from 1.53779 to 1.52184, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-47-with-1.5218.hdf5\n",
      "Epoch 48/120\n",
      "25862/25862 [==============================] - 6s 245us/step - loss: 1.5238\n",
      "\n",
      "Epoch 00048: loss did not improve from 1.52184\n",
      "Epoch 49/120\n",
      "25862/25862 [==============================] - 6s 227us/step - loss: 1.5267\n",
      "\n",
      "Epoch 00049: loss did not improve from 1.52184\n",
      "Epoch 50/120\n",
      "25862/25862 [==============================] - 6s 224us/step - loss: 1.5202\n",
      "\n",
      "Epoch 00050: loss improved from 1.52184 to 1.52020, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-50-with-1.5202.hdf5\n",
      "Epoch 51/120\n",
      "25862/25862 [==============================] - 6s 235us/step - loss: 1.4930\n",
      "\n",
      "Epoch 00051: loss improved from 1.52020 to 1.49302, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-51-with-1.4930.hdf5\n",
      "Epoch 52/120\n",
      "25862/25862 [==============================] - 6s 228us/step - loss: 1.4945\n",
      "\n",
      "Epoch 00052: loss did not improve from 1.49302\n",
      "Epoch 53/120\n",
      "25862/25862 [==============================] - 6s 228us/step - loss: 1.4644\n",
      "\n",
      "Epoch 00053: loss improved from 1.49302 to 1.46444, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-53-with-1.4644.hdf5\n",
      "Epoch 54/120\n",
      "25862/25862 [==============================] - 6s 239us/step - loss: 1.4374\n",
      "\n",
      "Epoch 00054: loss improved from 1.46444 to 1.43737, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-54-with-1.4374.hdf5\n",
      "Epoch 55/120\n",
      "25862/25862 [==============================] - 6s 240us/step - loss: 1.4543\n",
      "\n",
      "Epoch 00055: loss did not improve from 1.43737\n",
      "Epoch 56/120\n",
      "25862/25862 [==============================] - 7s 268us/step - loss: 1.4201\n",
      "\n",
      "Epoch 00056: loss improved from 1.43737 to 1.42010, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-56-with-1.4201.hdf5\n",
      "Epoch 57/120\n",
      "25862/25862 [==============================] - 7s 260us/step - loss: 1.4407 0s \n",
      "\n",
      "Epoch 00057: loss did not improve from 1.42010\n",
      "Epoch 58/120\n",
      "25862/25862 [==============================] - 7s 262us/step - loss: 1.4523\n",
      "\n",
      "Epoch 00058: loss did not improve from 1.42010\n",
      "Epoch 59/120\n",
      "25862/25862 [==============================] - 7s 289us/step - loss: 1.4052\n",
      "\n",
      "Epoch 00059: loss improved from 1.42010 to 1.40517, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-59-with-1.4052.hdf5\n",
      "Epoch 60/120\n",
      "25862/25862 [==============================] - 6s 231us/step - loss: 1.4200\n",
      "\n",
      "Epoch 00060: loss did not improve from 1.40517\n",
      "Epoch 61/120\n",
      "25862/25862 [==============================] - 6s 247us/step - loss: 1.3834\n",
      "\n",
      "Epoch 00061: loss improved from 1.40517 to 1.38343, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-61-with-1.3834.hdf5\n",
      "Epoch 62/120\n",
      "25862/25862 [==============================] - 8s 300us/step - loss: 1.3935\n",
      "\n",
      "Epoch 00062: loss did not improve from 1.38343\n",
      "Epoch 63/120\n",
      "25862/25862 [==============================] - 7s 269us/step - loss: 1.3693\n",
      "\n",
      "Epoch 00063: loss improved from 1.38343 to 1.36927, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-63-with-1.3693.hdf5\n",
      "Epoch 64/120\n",
      "25862/25862 [==============================] - 6s 243us/step - loss: 1.3718\n",
      "\n",
      "Epoch 00064: loss did not improve from 1.36927\n",
      "Epoch 65/120\n",
      "25862/25862 [==============================] - 7s 267us/step - loss: 1.3448\n",
      "\n",
      "Epoch 00065: loss improved from 1.36927 to 1.34484, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-65-with-1.3448.hdf5\n",
      "Epoch 66/120\n",
      "25862/25862 [==============================] - 8s 313us/step - loss: 1.3910\n",
      "\n",
      "Epoch 00066: loss did not improve from 1.34484\n",
      "Epoch 67/120\n",
      "25862/25862 [==============================] - 8s 324us/step - loss: 1.3796\n",
      "\n",
      "Epoch 00067: loss did not improve from 1.34484\n",
      "Epoch 68/120\n",
      "25862/25862 [==============================] - 7s 276us/step - loss: 1.3456\n",
      "\n",
      "Epoch 00068: loss did not improve from 1.34484\n",
      "Epoch 69/120\n",
      "25862/25862 [==============================] - 7s 287us/step - loss: 1.3096\n",
      "\n",
      "Epoch 00069: loss improved from 1.34484 to 1.30955, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-69-with-1.3096.hdf5\n",
      "Epoch 70/120\n",
      "25862/25862 [==============================] - 7s 273us/step - loss: 1.3355\n",
      "\n",
      "Epoch 00070: loss did not improve from 1.30955\n",
      "Epoch 71/120\n",
      "25862/25862 [==============================] - 7s 263us/step - loss: 1.3108\n",
      "\n",
      "Epoch 00071: loss did not improve from 1.30955\n",
      "Epoch 72/120\n",
      "25862/25862 [==============================] - 6s 244us/step - loss: 1.3248\n",
      "\n",
      "Epoch 00072: loss did not improve from 1.30955\n",
      "Epoch 73/120\n",
      "25862/25862 [==============================] - 7s 253us/step - loss: 1.3797\n",
      "\n",
      "Epoch 00073: loss did not improve from 1.30955\n",
      "Epoch 74/120\n",
      "25862/25862 [==============================] - 7s 259us/step - loss: 1.3121\n",
      "\n",
      "Epoch 00074: loss did not improve from 1.30955\n",
      "Epoch 75/120\n",
      "25862/25862 [==============================] - 6s 244us/step - loss: 1.2921\n",
      "\n",
      "Epoch 00075: loss improved from 1.30955 to 1.29207, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-75-with-1.2921.hdf5\n",
      "Epoch 76/120\n",
      "25862/25862 [==============================] - 6s 250us/step - loss: 1.3087\n",
      "\n",
      "Epoch 00076: loss did not improve from 1.29207\n",
      "Epoch 77/120\n",
      "25862/25862 [==============================] - 7s 261us/step - loss: 1.3185\n",
      "\n",
      "Epoch 00077: loss did not improve from 1.29207\n",
      "Epoch 78/120\n",
      "25862/25862 [==============================] - 6s 242us/step - loss: 1.3739\n",
      "\n",
      "Epoch 00078: loss did not improve from 1.29207\n",
      "Epoch 79/120\n",
      "25862/25862 [==============================] - 6s 244us/step - loss: 1.2740\n",
      "\n",
      "Epoch 00079: loss improved from 1.29207 to 1.27401, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-79-with-1.2740.hdf5\n",
      "Epoch 80/120\n",
      "25862/25862 [==============================] - 6s 246us/step - loss: 1.5536\n",
      "\n",
      "Epoch 00080: loss did not improve from 1.27401\n",
      "Epoch 81/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25862/25862 [==============================] - 7s 253us/step - loss: 1.3539\n",
      "\n",
      "Epoch 00081: loss did not improve from 1.27401\n",
      "Epoch 82/120\n",
      "25862/25862 [==============================] - 7s 265us/step - loss: 1.3183\n",
      "\n",
      "Epoch 00082: loss did not improve from 1.27401\n",
      "Epoch 83/120\n",
      "25862/25862 [==============================] - 7s 261us/step - loss: 1.3339\n",
      "\n",
      "Epoch 00083: loss did not improve from 1.27401\n",
      "Epoch 84/120\n",
      "25862/25862 [==============================] - 7s 254us/step - loss: 1.2781\n",
      "\n",
      "Epoch 00084: loss did not improve from 1.27401\n",
      "Epoch 85/120\n",
      "25862/25862 [==============================] - 6s 242us/step - loss: 1.2752\n",
      "\n",
      "Epoch 00085: loss did not improve from 1.27401\n",
      "Epoch 86/120\n",
      "25862/25862 [==============================] - 6s 240us/step - loss: 1.2878\n",
      "\n",
      "Epoch 00086: loss did not improve from 1.27401\n",
      "Epoch 87/120\n",
      "25862/25862 [==============================] - 6s 235us/step - loss: 1.2202\n",
      "\n",
      "Epoch 00087: loss improved from 1.27401 to 1.22022, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-87-with-1.2202.hdf5\n",
      "Epoch 88/120\n",
      "25862/25862 [==============================] - 6s 232us/step - loss: 1.1909\n",
      "\n",
      "Epoch 00088: loss improved from 1.22022 to 1.19093, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-88-with-1.1909.hdf5\n",
      "Epoch 89/120\n",
      "25862/25862 [==============================] - 6s 229us/step - loss: 1.2175\n",
      "\n",
      "Epoch 00089: loss did not improve from 1.19093\n",
      "Epoch 90/120\n",
      "25862/25862 [==============================] - 6s 226us/step - loss: 1.2084\n",
      "\n",
      "Epoch 00090: loss did not improve from 1.19093\n",
      "Epoch 91/120\n",
      "25862/25862 [==============================] - 6s 233us/step - loss: 1.2473\n",
      "\n",
      "Epoch 00091: loss did not improve from 1.19093\n",
      "Epoch 92/120\n",
      "25862/25862 [==============================] - 6s 230us/step - loss: 1.2298\n",
      "\n",
      "Epoch 00092: loss did not improve from 1.19093\n",
      "Epoch 93/120\n",
      "25862/25862 [==============================] - 6s 225us/step - loss: 1.2370\n",
      "\n",
      "Epoch 00093: loss did not improve from 1.19093\n",
      "Epoch 94/120\n",
      "25862/25862 [==============================] - 6s 224us/step - loss: 1.3211\n",
      "\n",
      "Epoch 00094: loss did not improve from 1.19093\n",
      "Epoch 95/120\n",
      "25862/25862 [==============================] - 6s 231us/step - loss: 1.2105\n",
      "\n",
      "Epoch 00095: loss did not improve from 1.19093\n",
      "Epoch 96/120\n",
      "25862/25862 [==============================] - 6s 225us/step - loss: 1.3411\n",
      "\n",
      "Epoch 00096: loss did not improve from 1.19093\n",
      "Epoch 97/120\n",
      "25862/25862 [==============================] - 6s 226us/step - loss: 1.2016\n",
      "\n",
      "Epoch 00097: loss did not improve from 1.19093\n",
      "Epoch 98/120\n",
      "25862/25862 [==============================] - 6s 224us/step - loss: 1.1814\n",
      "\n",
      "Epoch 00098: loss improved from 1.19093 to 1.18138, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-98-with-1.1814.hdf5\n",
      "Epoch 99/120\n",
      "25862/25862 [==============================] - 6s 226us/step - loss: 1.1565 0s -\n",
      "\n",
      "Epoch 00099: loss improved from 1.18138 to 1.15650, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-99-with-1.1565.hdf5\n",
      "Epoch 100/120\n",
      "25862/25862 [==============================] - 6s 239us/step - loss: 1.2078\n",
      "\n",
      "Epoch 00100: loss did not improve from 1.15650\n",
      "Epoch 101/120\n",
      "25862/25862 [==============================] - 6s 226us/step - loss: 1.2084\n",
      "\n",
      "Epoch 00101: loss did not improve from 1.15650\n",
      "Epoch 102/120\n",
      "25862/25862 [==============================] - 6s 227us/step - loss: 1.3884\n",
      "\n",
      "Epoch 00102: loss did not improve from 1.15650\n",
      "Epoch 103/120\n",
      "25862/25862 [==============================] - 6s 226us/step - loss: 1.1644\n",
      "\n",
      "Epoch 00103: loss did not improve from 1.15650\n",
      "Epoch 104/120\n",
      "25862/25862 [==============================] - 6s 243us/step - loss: 1.2416\n",
      "\n",
      "Epoch 00104: loss did not improve from 1.15650\n",
      "Epoch 105/120\n",
      "25862/25862 [==============================] - 6s 229us/step - loss: 1.1637\n",
      "\n",
      "Epoch 00105: loss did not improve from 1.15650\n",
      "Epoch 106/120\n",
      "25862/25862 [==============================] - 6s 226us/step - loss: 1.2152\n",
      "\n",
      "Epoch 00106: loss did not improve from 1.15650\n",
      "Epoch 107/120\n",
      "25862/25862 [==============================] - 6s 233us/step - loss: 1.1961\n",
      "\n",
      "Epoch 00107: loss did not improve from 1.15650\n",
      "Epoch 108/120\n",
      "25862/25862 [==============================] - 6s 226us/step - loss: 1.2200\n",
      "\n",
      "Epoch 00108: loss did not improve from 1.15650\n",
      "Epoch 109/120\n",
      "25862/25862 [==============================] - 6s 225us/step - loss: 1.1535\n",
      "\n",
      "Epoch 00109: loss improved from 1.15650 to 1.15354, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-109-with-1.1535.hdf5\n",
      "Epoch 110/120\n",
      "25862/25862 [==============================] - 6s 226us/step - loss: 1.1558\n",
      "\n",
      "Epoch 00110: loss did not improve from 1.15354\n",
      "Epoch 111/120\n",
      "25862/25862 [==============================] - 6s 231us/step - loss: 1.2648\n",
      "\n",
      "Epoch 00111: loss did not improve from 1.15354\n",
      "Epoch 112/120\n",
      "25862/25862 [==============================] - 6s 229us/step - loss: 1.1832\n",
      "\n",
      "Epoch 00112: loss did not improve from 1.15354\n",
      "Epoch 113/120\n",
      "25862/25862 [==============================] - 6s 229us/step - loss: 1.1493\n",
      "\n",
      "Epoch 00113: loss improved from 1.15354 to 1.14934, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-113-with-1.1493.hdf5\n",
      "Epoch 114/120\n",
      "25862/25862 [==============================] - 6s 242us/step - loss: 1.1216\n",
      "\n",
      "Epoch 00114: loss improved from 1.14934 to 1.12156, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-114-with-1.1216.hdf5\n",
      "Epoch 115/120\n",
      "25862/25862 [==============================] - 6s 237us/step - loss: 1.1407\n",
      "\n",
      "Epoch 00115: loss did not improve from 1.12156\n",
      "Epoch 116/120\n",
      "25862/25862 [==============================] - 6s 248us/step - loss: 1.2211\n",
      "\n",
      "Epoch 00116: loss did not improve from 1.12156\n",
      "Epoch 117/120\n",
      "25862/25862 [==============================] - 6s 229us/step - loss: 1.1432\n",
      "\n",
      "Epoch 00117: loss did not improve from 1.12156\n",
      "Epoch 118/120\n",
      "25862/25862 [==============================] - 6s 229us/step - loss: 1.1521\n",
      "\n",
      "Epoch 00118: loss did not improve from 1.12156\n",
      "Epoch 119/120\n",
      "25862/25862 [==============================] - 6s 229us/step - loss: 1.1709\n",
      "\n",
      "Epoch 00119: loss did not improve from 1.12156\n",
      "Epoch 120/120\n",
      "25862/25862 [==============================] - 6s 230us/step - loss: 1.1658\n",
      "\n",
      "Epoch 00120: loss did not improve from 1.12156\n"
     ]
    }
   ],
   "source": [
    "hist1 = model1.fit(x, y,\n",
    "              batch_size = batch_size,\n",
    "              epochs = option['epochs'],\n",
    "              callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь приступим к генерации текста. Мы загружаем лучшие веса (наименьшая потеря) уже обученной нейросети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.load_weights('C:/Users/hui/Desktop/AI/training_checkpoints_2/best-weights-on-114-with-1.1216.hdf5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настраиваем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 128)               24064     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 59)                7611      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 59)                0         \n",
      "=================================================================\n",
      "Total params: 31,675\n",
      "Trainable params: 31,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, gen_length):\n",
    "    # Зададим вариативность\n",
    "    diversity = 1.0\n",
    "    # Начало генерируемого текста\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    print(sentence)\n",
    "    # Запускаем посимвольную генерацию\n",
    "    for i in range(gen_length):\n",
    "        # Создаем массив нулей, в который запишем векторы символов входной строки\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        # Используем модель для прогнозирования\n",
    "        preds = model.predict(x_pred, verbose = 0)[0]\n",
    "        # Получаем наиболее вероятный индекс следующего символа по предсказаниям нейросети\n",
    "        next_index = sample(preds, diversity)\n",
    "        # Наиболее вероятный следующий символ по полученному индексу\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайно выбираем начало входной последовательности и сгенерируем текст по уже обученной нейросети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ни никак не могут представить себе этот \n",
      "потровую шилобыл польвотав поремут.\n",
      " - ду, кой расть зреглы и когданих: гаровзо! в донь я будре трудо - вузныхраташнов еспь ина долая ни потут баласукий чество. но вытил савые чудо продол вылом ем. гоговели шик с чного. и учты \". мебарить пон мог, - с азакая нем радеть и потсли ним шедить десь озжезнь.\n",
      " ногов е прадужетал онобо вуркеши волочео - оприсмалоть б-ладата ствеспо.\n",
      " - покая, - какотвают у пнох...\"и ризупель дебя да пестыте тетеко.\n",
      " - аси стался, чтостувенься, - спросил мол цветал сакдел нугды.\n",
      " - вотил мне редь? когда дежевдя гдямери\"ь пробочитать, чтобы придемиять. планетеют, что да, он и инесилня:\n",
      " - коз чно бельнови воврим е пудеметел серицасям мне оме челнот сямнца. млочен ещи дов дали он бедь, ма, но я быв посомать и тарослюни гдома ся нас оде жизал онае склотый пусьнем никой и скараастллянни\n",
      " - значше моляшь... не пужемнять полихним я но не кардатселы тиросниросвар, что сприсли, ис м очуго увидут потолпат, провотруя в почши, л е пенахздулосе винцо.\n",
      " - кугода те твсемник, поковуг задьси гаядой мыл тыветыл смбетрезньядь, каск стень салься?\n",
      " - ворисны уременя о споинеть? то был не тепящикого покном, го олконужмыень огливая моесто, и тыл калы проспоть лесте саром чешь?\n",
      "\n",
      "\n",
      " \u0014xiiiiiъ\n",
      "\n",
      "\n",
      " - микопот, на огом. я весьволком.\n",
      " точерою пиинить, чтобу цветвид не вебеонь, и ответол жилсть о ток м даше сластееньй. и мылня.\n",
      " - он, жна носо мегланек... и подну спрося не ках вскола оночьоб в ссещеи тно молчиту шкал ина совсегдв и скуюдл гу.\n",
      "ы- илисти мнечистоль онпещнижа те бебло\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "print(generate_text(model1, start_string = text[start_index: start_index + maxlen], gen_length = gen_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на значение потерь на обучающих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потери на данных\n",
      "loss: 1.051\n"
     ]
    }
   ],
   "source": [
    "test_acc = model1.evaluate(x, y, verbose = 2)\n",
    "print(\"Потери на данных\")\n",
    "print(\"%s: %.3f\" % (model1.metrics_names[0], test_acc)) # loss (потери)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим график потерь для простой полносвязной RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist1.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: значение потерь равно 1.051 по уже обученной нейросети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь приступим к однослойной LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               96256     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 59)                7611      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 59)                0         \n",
      "=================================================================\n",
      "Total params: 103,867\n",
      "Trainable params: 103,867\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/120\n",
      "25862/25862 [==============================] - 26s 997us/step - loss: 3.3243\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.32428, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-01-with-3.3243.hdf5\n",
      "Epoch 2/120\n",
      "25862/25862 [==============================] - 24s 921us/step - loss: 3.1324\n",
      "\n",
      "Epoch 00002: loss improved from 3.32428 to 3.13239, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-02-with-3.1324.hdf5\n",
      "Epoch 3/120\n",
      "25862/25862 [==============================] - 23s 898us/step - loss: 2.9784\n",
      "\n",
      "Epoch 00003: loss improved from 3.13239 to 2.97836, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-03-with-2.9784.hdf5\n",
      "Epoch 4/120\n",
      "25862/25862 [==============================] - 23s 898us/step - loss: 2.7878\n",
      "\n",
      "Epoch 00004: loss improved from 2.97836 to 2.78777, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-04-with-2.7878.hdf5\n",
      "Epoch 5/120\n",
      "25862/25862 [==============================] - 24s 912us/step - loss: 2.6457\n",
      "\n",
      "Epoch 00005: loss improved from 2.78777 to 2.64568, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-05-with-2.6457.hdf5\n",
      "Epoch 6/120\n",
      "25862/25862 [==============================] - 23s 878us/step - loss: 2.5564\n",
      "\n",
      "Epoch 00006: loss improved from 2.64568 to 2.55641, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-06-with-2.5564.hdf5\n",
      "Epoch 7/120\n",
      "25862/25862 [==============================] - 23s 883us/step - loss: 2.4937\n",
      "\n",
      "Epoch 00007: loss improved from 2.55641 to 2.49372, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-07-with-2.4937.hdf5\n",
      "Epoch 8/120\n",
      "25862/25862 [==============================] - 23s 885us/step - loss: 2.4408\n",
      "\n",
      "Epoch 00008: loss improved from 2.49372 to 2.44082, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-08-with-2.4408.hdf5\n",
      "Epoch 9/120\n",
      "25862/25862 [==============================] - 24s 937us/step - loss: 2.4007\n",
      "\n",
      "Epoch 00009: loss improved from 2.44082 to 2.40071, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-09-with-2.4007.hdf5\n",
      "Epoch 10/120\n",
      "25862/25862 [==============================] - 25s 978us/step - loss: 2.3653\n",
      "\n",
      "Epoch 00010: loss improved from 2.40071 to 2.36530, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-10-with-2.3653.hdf5\n",
      "Epoch 11/120\n",
      "25862/25862 [==============================] - 24s 920us/step - loss: 2.3411\n",
      "\n",
      "Epoch 00011: loss improved from 2.36530 to 2.34108, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-11-with-2.3411.hdf5\n",
      "Epoch 12/120\n",
      "25862/25862 [==============================] - 24s 924us/step - loss: 2.3069\n",
      "\n",
      "Epoch 00012: loss improved from 2.34108 to 2.30686, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-12-with-2.3069.hdf5\n",
      "Epoch 13/120\n",
      "25862/25862 [==============================] - 24s 913us/step - loss: 2.2842\n",
      "\n",
      "Epoch 00013: loss improved from 2.30686 to 2.28419, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-13-with-2.2842.hdf5\n",
      "Epoch 14/120\n",
      "25862/25862 [==============================] - 23s 906us/step - loss: 2.2565\n",
      "\n",
      "Epoch 00014: loss improved from 2.28419 to 2.25652, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-14-with-2.2565.hdf5\n",
      "Epoch 15/120\n",
      "25862/25862 [==============================] - 24s 914us/step - loss: 2.2415\n",
      "\n",
      "Epoch 00015: loss improved from 2.25652 to 2.24149, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-15-with-2.2415.hdf5\n",
      "Epoch 16/120\n",
      "25862/25862 [==============================] - 23s 907us/step - loss: 2.2205\n",
      "\n",
      "Epoch 00016: loss improved from 2.24149 to 2.22047, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-16-with-2.2205.hdf5\n",
      "Epoch 17/120\n",
      "25862/25862 [==============================] - 23s 882us/step - loss: 2.1962\n",
      "\n",
      "Epoch 00017: loss improved from 2.22047 to 2.19622, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-17-with-2.1962.hdf5\n",
      "Epoch 18/120\n",
      "25862/25862 [==============================] - 23s 880us/step - loss: 2.1743\n",
      "\n",
      "Epoch 00018: loss improved from 2.19622 to 2.17426, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-18-with-2.1743.hdf5\n",
      "Epoch 19/120\n",
      "25862/25862 [==============================] - 23s 898us/step - loss: 2.1611\n",
      "\n",
      "Epoch 00019: loss improved from 2.17426 to 2.16105, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-19-with-2.1611.hdf5\n",
      "Epoch 20/120\n",
      "25862/25862 [==============================] - 24s 928us/step - loss: 2.1322\n",
      "\n",
      "Epoch 00020: loss improved from 2.16105 to 2.13216, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-20-with-2.1322.hdf5\n",
      "Epoch 21/120\n",
      "25862/25862 [==============================] - 24s 912us/step - loss: 2.1197\n",
      "\n",
      "Epoch 00021: loss improved from 2.13216 to 2.11974, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-21-with-2.1197.hdf5\n",
      "Epoch 22/120\n",
      "25862/25862 [==============================] - 24s 915us/step - loss: 2.1006\n",
      "\n",
      "Epoch 00022: loss improved from 2.11974 to 2.10061, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-22-with-2.1006.hdf5\n",
      "Epoch 23/120\n",
      "25862/25862 [==============================] - 24s 918us/step - loss: 2.0802\n",
      "\n",
      "Epoch 00023: loss improved from 2.10061 to 2.08024, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-23-with-2.0802.hdf5\n",
      "Epoch 24/120\n",
      "25862/25862 [==============================] - 24s 916us/step - loss: 2.0647\n",
      "\n",
      "Epoch 00024: loss improved from 2.08024 to 2.06468, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-24-with-2.0647.hdf5\n",
      "Epoch 25/120\n",
      "25862/25862 [==============================] - 23s 877us/step - loss: 2.0433\n",
      "\n",
      "Epoch 00025: loss improved from 2.06468 to 2.04328, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-25-with-2.0433.hdf5\n",
      "Epoch 26/120\n",
      "25862/25862 [==============================] - 24s 910us/step - loss: 2.0253\n",
      "\n",
      "Epoch 00026: loss improved from 2.04328 to 2.02527, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-26-with-2.0253.hdf5\n",
      "Epoch 27/120\n",
      "25862/25862 [==============================] - 23s 880us/step - loss: 2.0138\n",
      "\n",
      "Epoch 00027: loss improved from 2.02527 to 2.01383, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-27-with-2.0138.hdf5\n",
      "Epoch 28/120\n",
      "25862/25862 [==============================] - 23s 876us/step - loss: 1.9983\n",
      "\n",
      "Epoch 00028: loss improved from 2.01383 to 1.99830, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-28-with-1.9983.hdf5\n",
      "Epoch 29/120\n",
      "25862/25862 [==============================] - 23s 905us/step - loss: 1.9755\n",
      "\n",
      "Epoch 00029: loss improved from 1.99830 to 1.97554, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-29-with-1.9755.hdf5\n",
      "Epoch 30/120\n",
      "25862/25862 [==============================] - 24s 925us/step - loss: 1.9652\n",
      "\n",
      "Epoch 00030: loss improved from 1.97554 to 1.96522, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-30-with-1.9652.hdf5\n",
      "Epoch 31/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25862/25862 [==============================] - 23s 886us/step - loss: 1.9526\n",
      "\n",
      "Epoch 00031: loss improved from 1.96522 to 1.95257, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-31-with-1.9526.hdf5\n",
      "Epoch 32/120\n",
      "25862/25862 [==============================] - 23s 897us/step - loss: 1.9304\n",
      "\n",
      "Epoch 00032: loss improved from 1.95257 to 1.93037, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-32-with-1.9304.hdf5\n",
      "Epoch 33/120\n",
      "25862/25862 [==============================] - 23s 907us/step - loss: 1.9106\n",
      "\n",
      "Epoch 00033: loss improved from 1.93037 to 1.91056, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-33-with-1.9106.hdf5\n",
      "Epoch 34/120\n",
      "25862/25862 [==============================] - 24s 917us/step - loss: 1.8936\n",
      "\n",
      "Epoch 00034: loss improved from 1.91056 to 1.89365, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-34-with-1.8936.hdf5\n",
      "Epoch 35/120\n",
      "25862/25862 [==============================] - 23s 891us/step - loss: 1.8800\n",
      "\n",
      "Epoch 00035: loss improved from 1.89365 to 1.87996, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-35-with-1.8800.hdf5\n",
      "Epoch 36/120\n",
      "25862/25862 [==============================] - 24s 918us/step - loss: 1.8723\n",
      "\n",
      "Epoch 00036: loss improved from 1.87996 to 1.87234, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-36-with-1.8723.hdf5\n",
      "Epoch 37/120\n",
      "25862/25862 [==============================] - 23s 904us/step - loss: 1.8501\n",
      "\n",
      "Epoch 00037: loss improved from 1.87234 to 1.85014, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-37-with-1.8501.hdf5\n",
      "Epoch 38/120\n",
      "25862/25862 [==============================] - 23s 892us/step - loss: 1.8382\n",
      "\n",
      "Epoch 00038: loss improved from 1.85014 to 1.83821, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-38-with-1.8382.hdf5\n",
      "Epoch 39/120\n",
      "25862/25862 [==============================] - 23s 891us/step - loss: 1.8226\n",
      "\n",
      "Epoch 00039: loss improved from 1.83821 to 1.82256, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-39-with-1.8226.hdf5\n",
      "Epoch 40/120\n",
      "25862/25862 [==============================] - 23s 886us/step - loss: 1.7978\n",
      "\n",
      "Epoch 00040: loss improved from 1.82256 to 1.79782, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-40-with-1.7978.hdf5\n",
      "Epoch 41/120\n",
      "25862/25862 [==============================] - 23s 894us/step - loss: 1.7867\n",
      "\n",
      "Epoch 00041: loss improved from 1.79782 to 1.78671, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-41-with-1.7867.hdf5\n",
      "Epoch 42/120\n",
      "25862/25862 [==============================] - 23s 885us/step - loss: 1.7678\n",
      "\n",
      "Epoch 00042: loss improved from 1.78671 to 1.76781, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-42-with-1.7678.hdf5\n",
      "Epoch 43/120\n",
      "25862/25862 [==============================] - 23s 901us/step - loss: 1.7502\n",
      "\n",
      "Epoch 00043: loss improved from 1.76781 to 1.75023, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-43-with-1.7502.hdf5\n",
      "Epoch 44/120\n",
      "25862/25862 [==============================] - 23s 896us/step - loss: 1.7291\n",
      "\n",
      "Epoch 00044: loss improved from 1.75023 to 1.72912, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-44-with-1.7291.hdf5\n",
      "Epoch 45/120\n",
      "25862/25862 [==============================] - 24s 935us/step - loss: 1.7202\n",
      "\n",
      "Epoch 00045: loss improved from 1.72912 to 1.72018, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-45-with-1.7202.hdf5\n",
      "Epoch 46/120\n",
      "25862/25862 [==============================] - 23s 892us/step - loss: 1.7105\n",
      "\n",
      "Epoch 00046: loss improved from 1.72018 to 1.71054, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-46-with-1.7105.hdf5\n",
      "Epoch 47/120\n",
      "25862/25862 [==============================] - 24s 911us/step - loss: 1.6872\n",
      "\n",
      "Epoch 00047: loss improved from 1.71054 to 1.68717, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-47-with-1.6872.hdf5\n",
      "Epoch 48/120\n",
      "25862/25862 [==============================] - 26s 1ms/step - loss: 1.6664\n",
      "\n",
      "Epoch 00048: loss improved from 1.68717 to 1.66636, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-48-with-1.6664.hdf5\n",
      "Epoch 49/120\n",
      "25862/25862 [==============================] - 24s 944us/step - loss: 1.6511\n",
      "\n",
      "Epoch 00049: loss improved from 1.66636 to 1.65107, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-49-with-1.6511.hdf5\n",
      "Epoch 50/120\n",
      "25862/25862 [==============================] - 24s 938us/step - loss: 1.6314\n",
      "\n",
      "Epoch 00050: loss improved from 1.65107 to 1.63144, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-50-with-1.6314.hdf5\n",
      "Epoch 51/120\n",
      "25862/25862 [==============================] - 24s 933us/step - loss: 1.6158\n",
      "\n",
      "Epoch 00051: loss improved from 1.63144 to 1.61582, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-51-with-1.6158.hdf5\n",
      "Epoch 52/120\n",
      "25862/25862 [==============================] - 25s 970us/step - loss: 1.5989\n",
      "\n",
      "Epoch 00052: loss improved from 1.61582 to 1.59891, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-52-with-1.5989.hdf5\n",
      "Epoch 53/120\n",
      "25862/25862 [==============================] - 25s 950us/step - loss: 1.5748\n",
      "\n",
      "Epoch 00053: loss improved from 1.59891 to 1.57482, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-53-with-1.5748.hdf5\n",
      "Epoch 54/120\n",
      "25862/25862 [==============================] - 24s 936us/step - loss: 1.5653\n",
      "\n",
      "Epoch 00054: loss improved from 1.57482 to 1.56532, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-54-with-1.5653.hdf5\n",
      "Epoch 55/120\n",
      "25862/25862 [==============================] - 24s 913us/step - loss: 1.5381\n",
      "\n",
      "Epoch 00055: loss improved from 1.56532 to 1.53809, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-55-with-1.5381.hdf5\n",
      "Epoch 56/120\n",
      "25862/25862 [==============================] - 24s 931us/step - loss: 1.5284\n",
      "\n",
      "Epoch 00056: loss improved from 1.53809 to 1.52839, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-56-with-1.5284.hdf5\n",
      "Epoch 57/120\n",
      "25862/25862 [==============================] - 24s 931us/step - loss: 1.4978\n",
      "\n",
      "Epoch 00057: loss improved from 1.52839 to 1.49775, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-57-with-1.4978.hdf5\n",
      "Epoch 58/120\n",
      "25862/25862 [==============================] - 24s 919us/step - loss: 1.4987\n",
      "\n",
      "Epoch 00058: loss did not improve from 1.49775\n",
      "Epoch 59/120\n",
      "25862/25862 [==============================] - 23s 908us/step - loss: 1.4887\n",
      "\n",
      "Epoch 00059: loss improved from 1.49775 to 1.48874, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-59-with-1.4887.hdf5\n",
      "Epoch 60/120\n",
      "25862/25862 [==============================] - 23s 898us/step - loss: 1.4550\n",
      "\n",
      "Epoch 00060: loss improved from 1.48874 to 1.45496, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-60-with-1.4550.hdf5\n",
      "Epoch 61/120\n",
      "25862/25862 [==============================] - 23s 895us/step - loss: 1.4417\n",
      "\n",
      "Epoch 00061: loss improved from 1.45496 to 1.44172, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-61-with-1.4417.hdf5\n",
      "Epoch 62/120\n",
      "25862/25862 [==============================] - 24s 925us/step - loss: 1.4237\n",
      "\n",
      "Epoch 00062: loss improved from 1.44172 to 1.42365, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-62-with-1.4237.hdf5\n",
      "Epoch 63/120\n",
      "25862/25862 [==============================] - 24s 911us/step - loss: 1.4033\n",
      "\n",
      "Epoch 00063: loss improved from 1.42365 to 1.40335, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-63-with-1.4033.hdf5\n",
      "Epoch 64/120\n",
      "25862/25862 [==============================] - 24s 909us/step - loss: 1.3916\n",
      "\n",
      "Epoch 00064: loss improved from 1.40335 to 1.39163, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-64-with-1.3916.hdf5\n",
      "Epoch 65/120\n",
      "25862/25862 [==============================] - 23s 898us/step - loss: 1.3846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00065: loss improved from 1.39163 to 1.38456, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-65-with-1.3846.hdf5\n",
      "Epoch 66/120\n",
      "25862/25862 [==============================] - 23s 888us/step - loss: 1.3484\n",
      "\n",
      "Epoch 00066: loss improved from 1.38456 to 1.34843, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-66-with-1.3484.hdf5\n",
      "Epoch 67/120\n",
      "25862/25862 [==============================] - 23s 893us/step - loss: 1.3443\n",
      "\n",
      "Epoch 00067: loss improved from 1.34843 to 1.34432, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-67-with-1.3443.hdf5\n",
      "Epoch 68/120\n",
      "25862/25862 [==============================] - 23s 893us/step - loss: 1.3087\n",
      "\n",
      "Epoch 00068: loss improved from 1.34432 to 1.30872, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-68-with-1.3087.hdf5\n",
      "Epoch 69/120\n",
      "25862/25862 [==============================] - 23s 894us/step - loss: 1.3061\n",
      "\n",
      "Epoch 00069: loss improved from 1.30872 to 1.30610, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-69-with-1.3061.hdf5\n",
      "Epoch 70/120\n",
      "25862/25862 [==============================] - 24s 923us/step - loss: 1.3007\n",
      "\n",
      "Epoch 00070: loss improved from 1.30610 to 1.30065, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-70-with-1.3007.hdf5\n",
      "Epoch 71/120\n",
      "25862/25862 [==============================] - 24s 917us/step - loss: 1.2686\n",
      "\n",
      "Epoch 00071: loss improved from 1.30065 to 1.26863, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-71-with-1.2686.hdf5\n",
      "Epoch 72/120\n",
      "25862/25862 [==============================] - 23s 904us/step - loss: 1.2622\n",
      "\n",
      "Epoch 00072: loss improved from 1.26863 to 1.26216, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-72-with-1.2622.hdf5\n",
      "Epoch 73/120\n",
      "25862/25862 [==============================] - 23s 890us/step - loss: 1.2205\n",
      "\n",
      "Epoch 00073: loss improved from 1.26216 to 1.22054, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-73-with-1.2205.hdf5\n",
      "Epoch 74/120\n",
      "25862/25862 [==============================] - 24s 944us/step - loss: 1.2258\n",
      "\n",
      "Epoch 00074: loss did not improve from 1.22054\n",
      "Epoch 75/120\n",
      "25862/25862 [==============================] - 23s 886us/step - loss: 1.1967\n",
      "\n",
      "Epoch 00075: loss improved from 1.22054 to 1.19673, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-75-with-1.1967.hdf5\n",
      "Epoch 76/120\n",
      "25862/25862 [==============================] - 23s 894us/step - loss: 1.1680\n",
      "\n",
      "Epoch 00076: loss improved from 1.19673 to 1.16800, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-76-with-1.1680.hdf5\n",
      "Epoch 77/120\n",
      "25862/25862 [==============================] - 23s 901us/step - loss: 1.2066\n",
      "\n",
      "Epoch 00077: loss did not improve from 1.16800\n",
      "Epoch 78/120\n",
      "25862/25862 [==============================] - 23s 896us/step - loss: 1.1602\n",
      "\n",
      "Epoch 00078: loss improved from 1.16800 to 1.16018, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-78-with-1.1602.hdf5\n",
      "Epoch 79/120\n",
      "25862/25862 [==============================] - 23s 901us/step - loss: 1.1519\n",
      "\n",
      "Epoch 00079: loss improved from 1.16018 to 1.15186, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-79-with-1.1519.hdf5\n",
      "Epoch 80/120\n",
      "25862/25862 [==============================] - 23s 902us/step - loss: 1.1137\n",
      "\n",
      "Epoch 00080: loss improved from 1.15186 to 1.11374, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-80-with-1.1137.hdf5\n",
      "Epoch 81/120\n",
      "25862/25862 [==============================] - 23s 887us/step - loss: 1.1178\n",
      "\n",
      "Epoch 00081: loss did not improve from 1.11374\n",
      "Epoch 82/120\n",
      "25862/25862 [==============================] - 23s 902us/step - loss: 1.0919\n",
      "\n",
      "Epoch 00082: loss improved from 1.11374 to 1.09193, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-82-with-1.0919.hdf5\n",
      "Epoch 83/120\n",
      "25862/25862 [==============================] - 23s 904us/step - loss: 1.0904\n",
      "\n",
      "Epoch 00083: loss improved from 1.09193 to 1.09042, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-83-with-1.0904.hdf5\n",
      "Epoch 84/120\n",
      "25862/25862 [==============================] - 27s 1ms/step - loss: 1.0424\n",
      "\n",
      "Epoch 00084: loss improved from 1.09042 to 1.04244, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-84-with-1.0424.hdf5\n",
      "Epoch 85/120\n",
      "25862/25862 [==============================] - 26s 1ms/step - loss: 1.0386\n",
      "\n",
      "Epoch 00085: loss improved from 1.04244 to 1.03861, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-85-with-1.0386.hdf5\n",
      "Epoch 86/120\n",
      "25862/25862 [==============================] - 26s 1ms/step - loss: 1.0289\n",
      "\n",
      "Epoch 00086: loss improved from 1.03861 to 1.02886, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-86-with-1.0289.hdf5\n",
      "Epoch 87/120\n",
      "25862/25862 [==============================] - 25s 972us/step - loss: 1.0348\n",
      "\n",
      "Epoch 00087: loss did not improve from 1.02886\n",
      "Epoch 88/120\n",
      "25862/25862 [==============================] - 26s 1ms/step - loss: 1.0075\n",
      "\n",
      "Epoch 00088: loss improved from 1.02886 to 1.00754, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-88-with-1.0075.hdf5\n",
      "Epoch 89/120\n",
      "25862/25862 [==============================] - 23s 891us/step - loss: 0.9890\n",
      "\n",
      "Epoch 00089: loss improved from 1.00754 to 0.98898, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-89-with-0.9890.hdf5\n",
      "Epoch 90/120\n",
      "25862/25862 [==============================] - 24s 912us/step - loss: 0.9786\n",
      "\n",
      "Epoch 00090: loss improved from 0.98898 to 0.97861, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-90-with-0.9786.hdf5\n",
      "Epoch 91/120\n",
      "25862/25862 [==============================] - 24s 914us/step - loss: 0.9983\n",
      "\n",
      "Epoch 00091: loss did not improve from 0.97861\n",
      "Epoch 92/120\n",
      "25862/25862 [==============================] - 23s 887us/step - loss: 0.9701\n",
      "\n",
      "Epoch 00092: loss improved from 0.97861 to 0.97010, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-92-with-0.9701.hdf5\n",
      "Epoch 93/120\n",
      "25862/25862 [==============================] - 24s 909us/step - loss: 0.9333\n",
      "\n",
      "Epoch 00093: loss improved from 0.97010 to 0.93329, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-93-with-0.9333.hdf5\n",
      "Epoch 94/120\n",
      "25862/25862 [==============================] - 24s 942us/step - loss: 0.9066\n",
      "\n",
      "Epoch 00094: loss improved from 0.93329 to 0.90658, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-94-with-0.9066.hdf5\n",
      "Epoch 95/120\n",
      "25862/25862 [==============================] - 23s 908us/step - loss: 0.9226\n",
      "\n",
      "Epoch 00095: loss did not improve from 0.90658\n",
      "Epoch 96/120\n",
      "25862/25862 [==============================] - 24s 911us/step - loss: 0.9199\n",
      "\n",
      "Epoch 00096: loss did not improve from 0.90658\n",
      "Epoch 97/120\n",
      "25862/25862 [==============================] - 23s 906us/step - loss: 0.9118\n",
      "\n",
      "Epoch 00097: loss did not improve from 0.90658\n",
      "Epoch 98/120\n",
      "25862/25862 [==============================] - 24s 917us/step - loss: 0.9957\n",
      "\n",
      "Epoch 00098: loss did not improve from 0.90658\n",
      "Epoch 99/120\n",
      "25862/25862 [==============================] - 24s 929us/step - loss: 0.8753\n",
      "\n",
      "Epoch 00099: loss improved from 0.90658 to 0.87531, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-99-with-0.8753.hdf5\n",
      "Epoch 100/120\n",
      "25862/25862 [==============================] - 23s 898us/step - loss: 0.8546\n",
      "\n",
      "Epoch 00100: loss improved from 0.87531 to 0.85458, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-100-with-0.8546.hdf5\n",
      "Epoch 101/120\n",
      "25862/25862 [==============================] - 23s 897us/step - loss: 0.8523\n",
      "\n",
      "Epoch 00101: loss improved from 0.85458 to 0.85226, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-101-with-0.8523.hdf5\n",
      "Epoch 102/120\n",
      "25862/25862 [==============================] - 23s 893us/step - loss: 0.8537\n",
      "\n",
      "Epoch 00102: loss did not improve from 0.85226\n",
      "Epoch 103/120\n",
      "25862/25862 [==============================] - 23s 906us/step - loss: 0.8626\n",
      "\n",
      "Epoch 00103: loss did not improve from 0.85226\n",
      "Epoch 104/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25862/25862 [==============================] - 23s 891us/step - loss: 0.8415\n",
      "\n",
      "Epoch 00104: loss improved from 0.85226 to 0.84147, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-104-with-0.8415.hdf5\n",
      "Epoch 105/120\n",
      "25862/25862 [==============================] - 23s 891us/step - loss: 0.8394\n",
      "\n",
      "Epoch 00105: loss improved from 0.84147 to 0.83938, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-105-with-0.8394.hdf5\n",
      "Epoch 106/120\n",
      "25862/25862 [==============================] - 23s 894us/step - loss: 0.8279\n",
      "\n",
      "Epoch 00106: loss improved from 0.83938 to 0.82786, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-106-with-0.8279.hdf5\n",
      "Epoch 107/120\n",
      "25862/25862 [==============================] - 23s 892us/step - loss: 0.7859\n",
      "\n",
      "Epoch 00107: loss improved from 0.82786 to 0.78593, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-107-with-0.7859.hdf5\n",
      "Epoch 108/120\n",
      "25862/25862 [==============================] - 23s 898us/step - loss: 0.8185\n",
      "\n",
      "Epoch 00108: loss did not improve from 0.78593\n",
      "Epoch 109/120\n",
      "25862/25862 [==============================] - 23s 895us/step - loss: 0.8857\n",
      "\n",
      "Epoch 00109: loss did not improve from 0.78593\n",
      "Epoch 110/120\n",
      "25862/25862 [==============================] - 23s 885us/step - loss: 0.8666\n",
      "\n",
      "Epoch 00110: loss did not improve from 0.78593\n",
      "Epoch 111/120\n",
      "25862/25862 [==============================] - 22s 866us/step - loss: 0.7606\n",
      "\n",
      "Epoch 00111: loss improved from 0.78593 to 0.76060, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-111-with-0.7606.hdf5\n",
      "Epoch 112/120\n",
      "25862/25862 [==============================] - 22s 870us/step - loss: 0.7498\n",
      "\n",
      "Epoch 00112: loss improved from 0.76060 to 0.74981, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-112-with-0.7498.hdf5\n",
      "Epoch 113/120\n",
      "25862/25862 [==============================] - 23s 903us/step - loss: 0.7426\n",
      "\n",
      "Epoch 00113: loss improved from 0.74981 to 0.74259, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-113-with-0.7426.hdf5\n",
      "Epoch 114/120\n",
      "25862/25862 [==============================] - 23s 875us/step - loss: 0.7409\n",
      "\n",
      "Epoch 00114: loss improved from 0.74259 to 0.74087, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-114-with-0.7409.hdf5\n",
      "Epoch 115/120\n",
      "25862/25862 [==============================] - 22s 869us/step - loss: 0.7494\n",
      "\n",
      "Epoch 00115: loss did not improve from 0.74087\n",
      "Epoch 116/120\n",
      "25862/25862 [==============================] - 23s 872us/step - loss: 0.7253\n",
      "\n",
      "Epoch 00116: loss improved from 0.74087 to 0.72532, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-116-with-0.7253.hdf5\n",
      "Epoch 117/120\n",
      "25862/25862 [==============================] - 23s 874us/step - loss: 0.7056\n",
      "\n",
      "Epoch 00117: loss improved from 0.72532 to 0.70563, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-117-with-0.7056.hdf5\n",
      "Epoch 118/120\n",
      "25862/25862 [==============================] - 23s 878us/step - loss: 0.6828\n",
      "\n",
      "Epoch 00118: loss improved from 0.70563 to 0.68279, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-118-with-0.6828.hdf5\n",
      "Epoch 119/120\n",
      "25862/25862 [==============================] - 23s 878us/step - loss: 0.7632\n",
      "\n",
      "Epoch 00119: loss did not improve from 0.68279\n",
      "Epoch 120/120\n",
      "25862/25862 [==============================] - 23s 882us/step - loss: 0.7637\n",
      "\n",
      "Epoch 00120: loss did not improve from 0.68279\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "option = options[1]\n",
    "\n",
    "model2 = building_model(vocab_size = vocab_size, batch_size = batch_size, maxlen = maxlen)\n",
    "model2.summary()\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy', optimizer = 'adam')\n",
    "\n",
    "checkpoint_dir = 'C:/Users/hui/Desktop/AI/training_checkpoints_3/'\n",
    "filepath=\"C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-{epoch:02d}-with-{loss:.4f}.hdf5\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')\n",
    "\n",
    "hist2 = model2.fit(x, y,\n",
    "              batch_size = batch_size,\n",
    "              epochs = option['epochs'],\n",
    "              callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('C:/Users/hui/Desktop/AI/training_checkpoints_3/best-weights-on-118-with-0.6828.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               96256     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 59)                7611      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 59)                0         \n",
      "=================================================================\n",
      "Total params: 103,867\n",
      "Trainable params: 103,867\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " земле. при свете луны я смотрел на его \n",
      "оданаков распотаться, торово. мен жичуго нечам, что она она все даваю себя, и вы слешим, что калечец.\n",
      " - ис1- спросте!\n",
      " - во - сказал маень, - поромол был какочик, заазам маленький принц рупываю, и ублисит с бском ме бые, чествее, эти отповаю, и свотачал какаю либу усталиник полэтол тот гобя, и дажи ущакол ни уго лишел посоветиразно: чно о виже у пялас. у потуспе. вся подилать ях..- скажал она щилто, как пробторей сереслия, смоллящих. - что это ка зезным нечус, ты уткажелся.\n",
      " - привум лисчет бымо дебя, кот полушь, де в ризоват водрох, ески я послы но мня та заход у сем сахдется, залочая мнельков. но чтобы ясле либы пихвету емлы будет заствалсть?\n",
      " - не, -ткого накогда ну мужу.\n",
      " - в дохжелся у мая заков,ть глафма..\n",
      " - пришимал?\n",
      " - нечествен..\n",
      " - да деже\", - одномажил маленький принц был вед, пкищем, поваление солочао. это свошил ю слобия пранида малеський принц. - сказал он корочил нечим.\n",
      " - что было у какого линиве тводал. они даже ни говорму, - возпринллся был том покланеть загодансаказале:\n",
      " - точлочоон.\n",
      " - остобно, порослион дву маютнубу на вка прелешил...\n",
      " он наки полочий прощечего на олобы проста онеть делна. по-омо, как пробедть емо прислуть сказал себя, и они задеть. вак он иись люби, плинет смему в овиоправать зарреда.\n",
      " - ян. оннажин: в будем я ущал чело кказальесь пронечно, на он будешно. на зебуднои все все спразулае:\n",
      " - сказали...\n",
      " - это проко де хоел, он потему, онил покомол как я как да тих мне поковогваюл ест, что она у все просто мане киз. вое ходя оскалатья..\n",
      " -\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "print(generate_text(model2, start_string = text[start_index: start_index + maxlen], gen_length = gen_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потери на данных\n",
      "loss: 0.505\n"
     ]
    }
   ],
   "source": [
    "test_acc = model2.evaluate(x, y, verbose = 2)\n",
    "print(\"Потери на данных\")\n",
    "print(\"%s: %.3f\" % (model2.metrics_names[0], test_acc)) # loss (потери)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist2.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: заметно улучшение по потерям, значение потерь = 0.505, что лучше значения потерь у RNN. Прослеживается уже большее количество осмысленных слов, но большинство словоформ лишь приближенно походят на настоящие русские слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь приступим к двухслойной LSTM. Действия те же самые, изменятся лишь результаты, по которым я сделаю вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 40, 256)           323584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 59)                15163     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 59)                0         \n",
      "=================================================================\n",
      "Total params: 864,059\n",
      "Trainable params: 864,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "25862/25862 [==============================] - 184s 7ms/step - loss: 3.2881\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.28806, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-01-with-3.2881.hdf5\n",
      "Epoch 2/30\n",
      "25862/25862 [==============================] - 170s 7ms/step - loss: 3.1035\n",
      "\n",
      "Epoch 00002: loss improved from 3.28806 to 3.10350, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-02-with-3.1035.hdf5\n",
      "Epoch 3/30\n",
      "25862/25862 [==============================] - 170s 7ms/step - loss: 2.7772\n",
      "\n",
      "Epoch 00003: loss improved from 3.10350 to 2.77724, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-03-with-2.7772.hdf5\n",
      "Epoch 4/30\n",
      "25862/25862 [==============================] - 211s 8ms/step - loss: 2.5672\n",
      "\n",
      "Epoch 00004: loss improved from 2.77724 to 2.56720, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-04-with-2.5672.hdf5\n",
      "Epoch 5/30\n",
      "25862/25862 [==============================] - 201s 8ms/step - loss: 2.4537\n",
      "\n",
      "Epoch 00005: loss improved from 2.56720 to 2.45373, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-05-with-2.4537.hdf5\n",
      "Epoch 6/30\n",
      "25862/25862 [==============================] - 242s 9ms/step - loss: 2.3720\n",
      "\n",
      "Epoch 00006: loss improved from 2.45373 to 2.37200, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-06-with-2.3720.hdf5\n",
      "Epoch 7/30\n",
      "25862/25862 [==============================] - 213s 8ms/step - loss: 2.2960\n",
      "\n",
      "Epoch 00007: loss improved from 2.37200 to 2.29601, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-07-with-2.2960.hdf5\n",
      "Epoch 8/30\n",
      "25862/25862 [==============================] - 192s 7ms/step - loss: 2.2342\n",
      "\n",
      "Epoch 00008: loss improved from 2.29601 to 2.23421, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-08-with-2.2342.hdf5\n",
      "Epoch 9/30\n",
      "25862/25862 [==============================] - 183s 7ms/step - loss: 2.1758\n",
      "\n",
      "Epoch 00009: loss improved from 2.23421 to 2.17584, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-09-with-2.1758.hdf5\n",
      "Epoch 10/30\n",
      "25862/25862 [==============================] - 176s 7ms/step - loss: 2.1209\n",
      "\n",
      "Epoch 00010: loss improved from 2.17584 to 2.12091, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-10-with-2.1209.hdf5\n",
      "Epoch 11/30\n",
      "25862/25862 [==============================] - 176s 7ms/step - loss: 2.0794\n",
      "\n",
      "Epoch 00011: loss improved from 2.12091 to 2.07935, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-11-with-2.0794.hdf5\n",
      "Epoch 12/30\n",
      "25862/25862 [==============================] - 186s 7ms/step - loss: 2.0152\n",
      "\n",
      "Epoch 00012: loss improved from 2.07935 to 2.01518, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-12-with-2.0152.hdf5\n",
      "Epoch 13/30\n",
      "25862/25862 [==============================] - 178s 7ms/step - loss: 1.9861\n",
      "\n",
      "Epoch 00013: loss improved from 2.01518 to 1.98612, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-13-with-1.9861.hdf5\n",
      "Epoch 14/30\n",
      "25862/25862 [==============================] - 176s 7ms/step - loss: 1.9311\n",
      "\n",
      "Epoch 00014: loss improved from 1.98612 to 1.93105, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-14-with-1.9311.hdf5\n",
      "Epoch 15/30\n",
      "25862/25862 [==============================] - 175s 7ms/step - loss: 1.8783\n",
      "\n",
      "Epoch 00015: loss improved from 1.93105 to 1.87827, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-15-with-1.8783.hdf5\n",
      "Epoch 16/30\n",
      "25862/25862 [==============================] - 172s 7ms/step - loss: 1.8305\n",
      "\n",
      "Epoch 00016: loss improved from 1.87827 to 1.83052, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-16-with-1.8305.hdf5\n",
      "Epoch 17/30\n",
      "25862/25862 [==============================] - 176s 7ms/step - loss: 1.7919\n",
      "\n",
      "Epoch 00017: loss improved from 1.83052 to 1.79189, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-17-with-1.7919.hdf5\n",
      "Epoch 18/30\n",
      "25862/25862 [==============================] - 183s 7ms/step - loss: 1.7336\n",
      "\n",
      "Epoch 00018: loss improved from 1.79189 to 1.73363, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-18-with-1.7336.hdf5\n",
      "Epoch 19/30\n",
      "25862/25862 [==============================] - 258s 10ms/step - loss: 1.6644\n",
      "\n",
      "Epoch 00019: loss improved from 1.73363 to 1.66441, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-19-with-1.6644.hdf5\n",
      "Epoch 20/30\n",
      "25862/25862 [==============================] - 199s 8ms/step - loss: 1.6415\n",
      "\n",
      "Epoch 00020: loss improved from 1.66441 to 1.64152, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-20-with-1.6415.hdf5\n",
      "Epoch 21/30\n",
      "25862/25862 [==============================] - 179s 7ms/step - loss: 1.5719\n",
      "\n",
      "Epoch 00021: loss improved from 1.64152 to 1.57191, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-21-with-1.5719.hdf5\n",
      "Epoch 22/30\n",
      "25862/25862 [==============================] - 182s 7ms/step - loss: 1.5216\n",
      "\n",
      "Epoch 00022: loss improved from 1.57191 to 1.52162, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-22-with-1.5216.hdf5\n",
      "Epoch 23/30\n",
      "25862/25862 [==============================] - 178s 7ms/step - loss: 1.4795\n",
      "\n",
      "Epoch 00023: loss improved from 1.52162 to 1.47950, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-23-with-1.4795.hdf5\n",
      "Epoch 24/30\n",
      "25862/25862 [==============================] - 174s 7ms/step - loss: 1.4192\n",
      "\n",
      "Epoch 00024: loss improved from 1.47950 to 1.41916, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-24-with-1.4192.hdf5\n",
      "Epoch 25/30\n",
      "25862/25862 [==============================] - 171s 7ms/step - loss: 1.3777\n",
      "\n",
      "Epoch 00025: loss improved from 1.41916 to 1.37770, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-25-with-1.3777.hdf5\n",
      "Epoch 26/30\n",
      "25862/25862 [==============================] - 173s 7ms/step - loss: 1.3061\n",
      "\n",
      "Epoch 00026: loss improved from 1.37770 to 1.30606, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-26-with-1.3061.hdf5\n",
      "Epoch 27/30\n",
      "25862/25862 [==============================] - 176s 7ms/step - loss: 1.2549\n",
      "\n",
      "Epoch 00027: loss improved from 1.30606 to 1.25488, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-27-with-1.2549.hdf5\n",
      "Epoch 28/30\n",
      "25862/25862 [==============================] - 183s 7ms/step - loss: 1.1622\n",
      "\n",
      "Epoch 00028: loss improved from 1.25488 to 1.16225, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-28-with-1.1622.hdf5\n",
      "Epoch 29/30\n",
      "25862/25862 [==============================] - 193s 7ms/step - loss: 1.1038\n",
      "\n",
      "Epoch 00029: loss improved from 1.16225 to 1.10375, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-29-with-1.1038.hdf5\n",
      "Epoch 30/30\n",
      "25862/25862 [==============================] - 174s 7ms/step - loss: 1.0547\n",
      "\n",
      "Epoch 00030: loss improved from 1.10375 to 1.05473, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-30-with-1.0547.hdf5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "option = options[2]\n",
    "\n",
    "model3 = building_model(vocab_size = vocab_size, batch_size = batch_size, maxlen = maxlen)\n",
    "\n",
    "model3.summary()\n",
    "model3.compile(loss='categorical_crossentropy', optimizer = 'adam')\n",
    "\n",
    "checkpoint_dir = 'C:/Users/hui/Desktop/AI/training_checkpoints_4/'\n",
    "filepath = \"C:/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-{epoch:02d}-with-{loss:.4f}.hdf5\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')\n",
    "\n",
    "hist3 = model3.fit(x, y,\n",
    "              batch_size = batch_size,\n",
    "              epochs = option['epochs'],\n",
    "              callbacks = [checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.load_weights('/Users/hui/Desktop/AI/training_checkpoints_4/best-weights-on-30-with-1.0547.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 40, 256)           323584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 59)                15163     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 59)                0         \n",
      "=================================================================\n",
      "Total params: 864,059\n",
      "Trainable params: 864,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " еще отдавалось пенье скрипучего ворота,\n",
      " и вапил такум глотаки. и - понимался маленькимо принц.\n",
      " вот мни былу такогда так бы не кутку ну, она отбы радке то фвердцанед тводи никогта от, разны такее планетвыя. - это на будет я тучешь маленький принц. - на ответилия, ничебоя у немалобе\n",
      " - а ису уже поволясявся кого он истил...\n",
      " и после моголко, сладалка ответние\", и месте не пуслы мотроко этом пришесля будат сомжать имо, коточьо на могже только поверяет: сы простомут, од наможени и росит, - сказал я посям шисмо бы что можпоима\n",
      " и еде не ствем, так межный прислы я цветко естил был так на издание, человык сказал най отвыту. что знах вилоскаваять умеетерьенко пробутал ето стали гостах: ты вынянал езразты росость!\n",
      " и он потночал сторжевнем он скуза.\n",
      " мветь, сказал маленький принц весли на симые! сабовится нассказы: 1вадые все пускуху. он был, что больско могрыхо, а ты топьенно, это сыло желпую. и потубал все ухоме отимал когда..\n",
      " \u0014xii\u0015\n",
      "\n",
      " скажа на дешь, я точешколсто постартяя больше взролкот.\n",
      " - просто слошил бороком.\n",
      " - этот это жи говорим...\n",
      " - подумал маленький принц спросли не сертею этот росто так мне самого био посекравума твепе.\n",
      ".\n",
      " и ну хона хочет серед это же самореной полртому мог а как соброленнол у кая взрослые и резовитал може заводно я них он славал. твере, себя пустаня. тычиго бразустаяь тысчут лаз.. ты хотел, чтобы всо этой рию есень. и опланить ворох... схрисил маленькой денц.\n",
      " - все плакону поейвесте: я вись лы но чествеютка.\n",
      " - я все с насе веде иля мне ни остав тереейсе, вто ты исмиленься?\n",
      " - ничеободы \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "print(generate_text(model3, start_string = text[start_index: start_index + maxlen], gen_length = gen_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потери на данных\n",
      "loss: 0.781\n"
     ]
    }
   ],
   "source": [
    "test_acc = model3.evaluate(x, y, verbose = 2)\n",
    "print(\"Потери на данных\")\n",
    "print(\"%s: %.3f\" % (model3.metrics_names[0], test_acc)) # loss (потери)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist3.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: обучение данной нейросети занимает много времени, поэтому вместо обычных 120 эпох, я поставила значение 30. Значение потерь = 0.781. Различие не такое значительное, но нейросеть обучилась несколько хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец посмотрим как работает GRU . Действия те же самые, изменятся лишь результаты, по которым я сделаю вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 40, 256)           242688    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 59)                604219    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 59)                0         \n",
      "=================================================================\n",
      "Total params: 846,907\n",
      "Trainable params: 846,907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "25862/25862 [==============================] - 74s 3ms/step - loss: 3.1669\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.16693, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-01-with-3.1669.hdf5\n",
      "Epoch 2/25\n",
      "25862/25862 [==============================] - 68s 3ms/step - loss: 2.6519\n",
      "\n",
      "Epoch 00002: loss improved from 3.16693 to 2.65191, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-02-with-2.6519.hdf5\n",
      "Epoch 3/25\n",
      "25862/25862 [==============================] - 69s 3ms/step - loss: 2.2485\n",
      "\n",
      "Epoch 00003: loss improved from 2.65191 to 2.24849, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-03-with-2.2485.hdf5\n",
      "Epoch 4/25\n",
      "25862/25862 [==============================] - 67s 3ms/step - loss: 2.0248\n",
      "\n",
      "Epoch 00004: loss improved from 2.24849 to 2.02475, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-04-with-2.0248.hdf5\n",
      "Epoch 5/25\n",
      "25862/25862 [==============================] - 66s 3ms/step - loss: 1.8853\n",
      "\n",
      "Epoch 00005: loss improved from 2.02475 to 1.88534, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-05-with-1.8853.hdf5\n",
      "Epoch 6/25\n",
      "25862/25862 [==============================] - 69s 3ms/step - loss: 1.7782\n",
      "\n",
      "Epoch 00006: loss improved from 1.88534 to 1.77822, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-06-with-1.7782.hdf5\n",
      "Epoch 7/25\n",
      "25862/25862 [==============================] - 69s 3ms/step - loss: 1.6889\n",
      "\n",
      "Epoch 00007: loss improved from 1.77822 to 1.68888, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-07-with-1.6889.hdf5\n",
      "Epoch 8/25\n",
      "25862/25862 [==============================] - 73s 3ms/step - loss: 1.6152\n",
      "\n",
      "Epoch 00008: loss improved from 1.68888 to 1.61519, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-08-with-1.6152.hdf5\n",
      "Epoch 9/25\n",
      "25862/25862 [==============================] - 69s 3ms/step - loss: 1.5491\n",
      "\n",
      "Epoch 00009: loss improved from 1.61519 to 1.54912, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-09-with-1.5491.hdf5\n",
      "Epoch 10/25\n",
      "25862/25862 [==============================] - 69s 3ms/step - loss: 1.4786\n",
      "\n",
      "Epoch 00010: loss improved from 1.54912 to 1.47860, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-10-with-1.4786.hdf5\n",
      "Epoch 11/25\n",
      "25862/25862 [==============================] - 68s 3ms/step - loss: 1.4084\n",
      "\n",
      "Epoch 00011: loss improved from 1.47860 to 1.40838, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-11-with-1.4084.hdf5\n",
      "Epoch 12/25\n",
      "25862/25862 [==============================] - ETA: 0s - loss: 1.363 - 68s 3ms/step - loss: 1.3631\n",
      "\n",
      "Epoch 00012: loss improved from 1.40838 to 1.36314, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-12-with-1.3631.hdf5\n",
      "Epoch 13/25\n",
      "25862/25862 [==============================] - 67s 3ms/step - loss: 1.3097\n",
      "\n",
      "Epoch 00013: loss improved from 1.36314 to 1.30971, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-13-with-1.3097.hdf5\n",
      "Epoch 14/25\n",
      "25862/25862 [==============================] - 67s 3ms/step - loss: 1.2416\n",
      "\n",
      "Epoch 00014: loss improved from 1.30971 to 1.24156, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-14-with-1.2416.hdf5\n",
      "Epoch 15/25\n",
      "25862/25862 [==============================] - 67s 3ms/step - loss: 1.1723\n",
      "\n",
      "Epoch 00015: loss improved from 1.24156 to 1.17233, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-15-with-1.1723.hdf5\n",
      "Epoch 16/25\n",
      "25862/25862 [==============================] - 66s 3ms/step - loss: 1.0993\n",
      "\n",
      "Epoch 00016: loss improved from 1.17233 to 1.09930, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-16-with-1.0993.hdf5\n",
      "Epoch 17/25\n",
      "25862/25862 [==============================] - 68s 3ms/step - loss: 1.0357\n",
      "\n",
      "Epoch 00017: loss improved from 1.09930 to 1.03571, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-17-with-1.0357.hdf5\n",
      "Epoch 18/25\n",
      "25862/25862 [==============================] - 66s 3ms/step - loss: 0.9722\n",
      "\n",
      "Epoch 00018: loss improved from 1.03571 to 0.97215, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-18-with-0.9722.hdf5\n",
      "Epoch 19/25\n",
      "25862/25862 [==============================] - 66s 3ms/step - loss: 0.9002\n",
      "\n",
      "Epoch 00019: loss improved from 0.97215 to 0.90017, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-19-with-0.9002.hdf5\n",
      "Epoch 20/25\n",
      "25862/25862 [==============================] - 67s 3ms/step - loss: 0.7993\n",
      "\n",
      "Epoch 00020: loss improved from 0.90017 to 0.79935, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-20-with-0.7993.hdf5\n",
      "Epoch 21/25\n",
      "25862/25862 [==============================] - 71s 3ms/step - loss: 0.7193\n",
      "\n",
      "Epoch 00021: loss improved from 0.79935 to 0.71929, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-21-with-0.7193.hdf5\n",
      "Epoch 22/25\n",
      "25862/25862 [==============================] - 68s 3ms/step - loss: 0.6605\n",
      "\n",
      "Epoch 00022: loss improved from 0.71929 to 0.66051, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-22-with-0.6605.hdf5\n",
      "Epoch 23/25\n",
      "25862/25862 [==============================] - 67s 3ms/step - loss: 0.6084\n",
      "\n",
      "Epoch 00023: loss improved from 0.66051 to 0.60836, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-23-with-0.6084.hdf5\n",
      "Epoch 24/25\n",
      "25862/25862 [==============================] - 67s 3ms/step - loss: 0.5091\n",
      "\n",
      "Epoch 00024: loss improved from 0.60836 to 0.50909, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-24-with-0.5091.hdf5\n",
      "Epoch 25/25\n",
      "25862/25862 [==============================] - 67s 3ms/step - loss: 0.4237\n",
      "\n",
      "Epoch 00025: loss improved from 0.50909 to 0.42367, saving model to C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-25-with-0.4237.hdf5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "option = options[3]\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(GRU(option['size'], input_shape = (maxlen, vocab_size), return_sequences = True))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(vocab_size)) \n",
    "model4.add(Activation('softmax'))\n",
    "\n",
    "model4.summary()\n",
    "model4.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "\n",
    "checkpoint_dir = 'C:/Users/hui/Desktop/AI/training_checkpoints_5/'\n",
    "filepath = \"C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-{epoch:02d}-with-{loss:.4f}.hdf5\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')\n",
    "\n",
    "hist4 = model4.fit(x, y,\n",
    "              batch_size = batch_size,\n",
    "              epochs = option['epochs'],\n",
    "              callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.load_weights('C:/Users/hui/Desktop/AI/training_checkpoints_5/best-weights-on-25-with-0.4237.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 40, 256)           242688    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 59)                604219    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 59)                0         \n",
      "=================================================================\n",
      "Total params: 846,907\n",
      "Trainable params: 846,907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "иказания.\n",
      " \"если я повелю своему генерал\n",
      " не ий потит я всенеедот митвое на и всром опил котолый пирь удит, - сказал маленький принц. - вод ребовет стул не спак..и посдизесли но интю еть. - вод овдлевеел да по плунитить но и знаел и оних путьтох, иконочен- зрпртошо верив. и загда,.... подаялси с оснему ниго брабетол у помол опкак.\n",
      " - значто, можни ды в нетемо озвавдетсл доманьа свераток п непет. маленький принц ниветве но од болот. тобы роб саревурисание вринама?\n",
      " - полаветь ветира. аве выем ез олобу нато, како пляленем пидотвнал всего веле быля кразаслов.и он два маленький принц. но все вотоби поденаедан, неськитоть од но измил...\n",
      " - и заход шеле. ни геду ноя, что ду ленние мволичать присловмо словно мелу в рускумелия, - скажилить ни он малыно.\n",
      " - асть нахордртвстко тврем я на ого долил не верковит бодот привеним споон приветитам не такее претеднел из на он. все пленелого вок расниу преволитые, что всем расмеет я  так если ов встришамило ня наченсенилого, потся дать смалечто. подрес ветом топощоелида, взвовму тапь,дчешя не илпооне, но дал\n",
      " маленьким принц. я мил он сприселит, - оконир с одмаретьки подровци и посяжнио свовитьрино вееди. нау меня превудела мни боться и. задовнивай сонему правелие на пыстепмноесят на мил порешика паственал, что маленький плинц.\n",
      ", вае, в петер, у маленикой. ался и твезровут...\n",
      " -  на терекне.\n",
      " - все мне был на подправслис, в то был ше, - ствмне присляв.\n",
      " - понизь, то,  звокмительсо продим приня.\n",
      " - они, зканет и скожда табемния полнолить ен пикуважи водробу.\n",
      " - прастулот я ни толеное. \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "print(generate_text(model4, start_string = text[start_index: start_index + maxlen], gen_length = gen_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потери на данных\n",
      "loss: 0.201\n"
     ]
    }
   ],
   "source": [
    "test_acc = model4.evaluate(x, y, verbose = 2)\n",
    "print(\"Потери на данных\")\n",
    "print(\"%s: %.3f\" % (model4.metrics_names[0], test_acc)) # loss (потери)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXhU5d3/8fc3CwlL2JIAIQsBZVNWDciiCGirIlZtrWtd21qtrd1sbfv8ntY+a9undlG7abUuVaxVcbetKIqo7DuCCAgkIYSwJQQSsn1/f2SwSQyQQCZnMvN5XVcuZs45M/M9zmU+ue/7nPs2d0dEROSwuKALEBGRyKJgEBGRRhQMIiLSiIJBREQaUTCIiEgjCgYREWlEwSDSAmaWa2ZuZgktOPYGM5t/ou8jEhQFg0QdM9tiZlVmltZk+4rQL+XcYCoT6RgUDBKtPgKuOvzEzEYCnYMrR6TjUDBItHoMuK7B8+uBRxseYGY9zOxRMysxs61m9v/MLC60L97MfmFmu8xsM3BhM6990MyKzKzQzP7LzOJbW6SZ9TezF8xsj5ltNLMvN9g33syWmFmZmRWb2S9D25PN7C9mttvM9pnZYjPr29rPFjkSBYNEqwVAdzMbHvqFfQXwlybH3Av0AAYBZ1MfJDeG9n0ZmAmMBfKAy5q89hGgBjg5dMyngS8dR52zgAKgf+gz/sfMzgnt+w3wG3fvDpwEPBXafn2o7mwgFbgFqDiOzxZploJBotnhVsOngPVA4eEdDcLiB+6+3923AHcD14YOuRz4tbvnu/se4H8bvLYvcAHwTXc/4O47gV8BV7amODPLBs4E7nT3SndfAfypQQ3VwMlmlubu5e6+oMH2VOBkd69196XuXtaazxY5GgWDRLPHgKuBG2jSjQSkAZ2ArQ22bQUyQ4/7A/lN9h02AEgEikJdOfuAPwJ9Wllff2CPu+8/Qg1fBIYA60PdRTMbnNc/gCfNbLuZ/dzMElv52SJHpGCQqOXuW6kfhJ4BPNtk9y7q//Ie0GBbDv9qVRRR31XTcN9h+cAhIM3de4Z+urv7qa0scTvQ28xSmqvB3T9096uoD5yfAU+bWVd3r3b3n7j7KcAk6ru8rkOkjSgYJNp9EZju7gcabnT3Wur77P/bzFLMbADwbf41DvEUcLuZZZlZL+D7DV5bBPwTuNvMuptZnJmdZGZnt6Ywd88H3gX+NzSgPCpU7+MAZvYFM0t39zpgX+hltWY2zcxGhrrDyqgPuNrWfLbI0SgYJKq5+yZ3X3KE3V8HDgCbgfnAE8BDoX0PUN9dsxJYxidbHNdR3xX1PrAXeBrIOI4SrwJyqW89zAZ+7O6vhfadD6w1s3LqB6KvdPdKoF/o88qAdcBbfHJgXeS4mRbqERGRhtRiEBGRRhQMIiLSiIJBREQaUTCIiEgjHW7q37S0NM/NzQ26DBGRDmXp0qW73D29Jcd2uGDIzc1lyZIjXX0oIiLNMbOtxz6qnrqSRESkEQWDiIg0omAQEZFGOtwYQ3Oqq6spKCigsrIy6FLCLjk5maysLBITNZmmiIRHVARDQUEBKSkp5ObmYmZBlxM27s7u3bspKChg4MCBQZcjIlEqKrqSKisrSU1NjepQADAzUlNTY6JlJCLBiYpgAKI+FA6LlfMUkeBETTAcS2V1Ldv3VVCn2WRFRI4qZoKhqqaOXeWHKK+safP33r17N2PGjGHMmDH069ePzMzMj59XVVUd9bVLlizh9ttvb/OaRESOV1QMPrdEt+QE4uOMfRXVdO/ctlf0pKamsmLFCgDuuusuunXrxh133PHx/pqaGhISmv9PnZeXR15eXpvWIyJyImKmxRBnRo/kRMoqqqmrC3930g033MC3v/1tpk2bxp133smiRYuYNGkSY8eOZdKkSXzwwQcAvPnmm8ycWb/G+1133cVNN93E1KlTGTRoEPfcc0/Y6xQRaSrqWgw/eXEt728va3ZfbZ1TWV1LcmI88XEtH8Q9pX93fnxRa9d5hw0bNjBnzhzi4+MpKytj3rx5JCQkMGfOHH74wx/yzDPPfOI169evZ+7cuezfv5+hQ4dy66236p4FEWlXURcMRxMfZ5gZNXV1xMfFh/3zPv/5zxMfX/85paWlXH/99Xz44YeYGdXV1c2+5sILLyQpKYmkpCT69OlDcXExWVlZYa9VROSwqAuGY/1lX7i3gr0Hqxie0b1VrYbj0bVr148f//u//zvTpk1j9uzZbNmyhalTpzb7mqSkpI8fx8fHU1PT9oPlIiJHEzNjDIf16JJInTv7K5v/iz1cSktLyczMBODhhx9u188WEWmNmAuGrp3iSYyPY9/B9g2G733ve/zgBz9g8uTJ1NbWtutni4i0hnkHu+ErLy/Pmy7Us27dOoYPH97i99i+r4LdB6oYnpFCQlzHy8bWnq+IiJktdfcWXRsftt+KZpZsZovMbKWZrTWznzRzjJnZPWa20cxWmdlp4aqnoZ6dE3F3yirUfy8i0lQ4/1w+BEx399HAGOB8M5vQ5JgLgMGhn5uB34exno917hRPp/g4SivatztJRKQjCFsweL3y0NPE0E/TfquLgUdDxy4AeppZxnF+XouPNTN6dEmkvLKGmtq64/m4wHS0rj8R6XjC2sFuZvFmtgLYCbzm7gubHJIJ5Dd4XhDa1vR9bjazJWa2pKSk5BOfk5yczO7du1v1S7Nn50Qc71CthsPrMSQnJwddiohEsbDex+DutcAYM+sJzDazEe6+psEhzd1I8Inf7u5+P3A/1A8+N92flZVFQUEBzYXG0ewpq2TfdiM9JenYB0eIwyu4iYiES7vc4Obu+8zsTeB8oGEwFADZDZ5nAdtb+/6JiYnHtaLZq//8gHvnbmThD86hT3f9FS4iAuG9Kik91FLAzDoD5wLrmxz2AnBd6OqkCUCpuxeFq6amLhrdH3d4ZXW7faSISMQL5xhDBjDXzFYBi6kfY3jJzG4xs1tCx7wCbAY2Ag8AXw1jPZ8wuG8KQ/um8NIqBYOIyGFh60py91XA2Ga2/6HBYwduC1cNLXHR6Ax+8c8NbN9XQf+enYMsRUQkInS8237b2MxR/QF4Wa0GERFAwUBuWldGZvbgxVWtHvMWEYlKMR8MADNHZbCqoJStuw8EXYqISOAUDMCFo+pvttYgtIiIggGArF5dOC2nJy+uVHeSiIiCIeSi0f1Zv2M/G3fuD7oUEZFAKRhCZozMwAxeXKnuJBGJbQqGkL7dkzljYG9eWrVdM5iKSExTMDQwc1R/NpUcYF2RupNEJHYpGBq4YEQ/4uOMl3RPg4jEMAVDA6ndkph0UiovqjtJRGKYgqGJi0b1J39PBasKSoMuRUQkEAqGJs47tR+J8aZ7GkQkZikYmujRJZEpg9N5eXURdXXqThKR2KNgaMZFo/tTVFrJ0m17gy5FRKTdKRiace4pfUlKiOMldSeJSAxSMDSjW1IC04f14eXVO6hVd5KIxBgFwxHMHNWfXeWHWLh5d9CliIi0KwXDEUwf1ocuneK1gI+IxBwFwxF07hTPp0/py0urijhwqCbockRE2o2C4SiunZjL/soanllWEHQpIiLtRsFwFKfl9GR0dk/+/M4W3dMgIjFDwXAUZsZNk3P5aNcB3tpQEnQ5IiLtQsFwDBeMyKBv9yQeeuejoEsREWkXCoZj6JQQx3UTc3n7w11sKNY6DSIS/RQMLXDV+BySEuL48ztbgi5FRCTsFAwt0LtrJy4dm8mzywrYe6Aq6HJERMIqbMFgZtlmNtfM1pnZWjP7RjPHTDWzUjNbEfr5UbjqOVE3Th7IoZo6nli0LehSRETCKpwthhrgO+4+HJgA3GZmpzRz3NvuPib08x9hrOeEDO2Xwpknp/HYe1uprq0LuhwRkbAJWzC4e5G7Lws93g+sAzLD9Xnt4cbJuewoq+TVNTuCLkVEJGzaZYzBzHKBscDCZnZPNLOVZvaqmZ16hNffbGZLzGxJSUlw9xNMG9qH3NQuPDRfl66KSPQKezCYWTfgGeCb7l7WZPcyYIC7jwbuBZ5r7j3c/X53z3P3vPT09PAWfBRxccaNkweyIn8fy7SIj4hEqbAGg5klUh8Kj7v7s033u3uZu5eHHr8CJJpZWjhrOlGfOz2LlKQEXboqIlErnFclGfAgsM7df3mEY/qFjsPMxofqiegFELolJXDFuGxeWV1EUWlF0OWIiLS5cLYYJgPXAtMbXI46w8xuMbNbQsdcBqwxs5XAPcCV7h7xs9VdPykXd+ex97YGXYqISJtLCNcbu/t8wI5xzH3AfeGqIVyye3fhU6f05YlF2/j69MF07hQfdEkiIm1Gdz4fp5smD2TfwWpmLy8MuhQRkTalYDhO4wf25tT+3fnzOx/RAXq/RERaTMFwnOrXahjIhzvLmb9xV9DliIi0GQXDCZg5OoO0bkm64U1EooqC4QQkJcTzhQk5zP2ghM0l5UGXIyLSJhQMJ+iaMwbQKT6Oh9/dEnQpIiJtQsFwgtJTkrhodH+eXlpAaUV10OWIiJwwBUMbuHFyLgeranlqcX7QpYiInDAFQxsYkdmDMwb25uF3t1CjtRpEpINTMLSRGycPpHBfBa+9Xxx0KSIiJ0TB0EY+dUpfsnp11qyrItLhKRjaSHycccOkXBZt2cPqgtKgyxEROW4KhjZ0+bhsUpIS+NELa6iq0ViDiHRMCoY21D05kZ9+bhTLt+3jP196P+hyRESOi4KhjV04KoObpwzisQVbeXppQdDliIi0moIhDL533lAmDkrl32avZk2hxhtEpGNRMIRBQnwc9149lt5dO3HLX5ay90BV0CWJiLSYgiFM0rol8fsvnM7OskPc/uRyauu0ZoOIdAwKhjAak92Tuz5zKm9/uItfvbYh6HJERFpEwRBmV43P5oq8bO6bu5F/rt0RdDkiIsekYAgzM+MnF5/KqKwefOeplVq3QUQinoKhHSQnxvP7L5xOYkIcX3lsKQcO1QRdkojIESkY2klmz87ce9VYNpWU872nV+GuwWgRiUwKhnY0+eQ0vnveMF5eXcSf3tY60SISmRQM7eyWswdxwYh+/PTv63l3066gyxER+QQFQzszM/7v86PJTe3C159YzvZ9FUGXJCLSiIIhAN2SEvjjtXlUVtdy6+PLOFRTG3RJIiIfC1swmFm2mc01s3VmttbMvtHMMWZm95jZRjNbZWanhaueSHNyn27cffloVubv464XNBOriESOcLYYaoDvuPtwYAJwm5md0uSYC4DBoZ+bgd+HsZ6Ic/6IDG45+yRmLdrGD2evVstBRCJCQrje2N2LgKLQ4/1mtg7IBBr+eXwx8KjXX7u5wMx6mllG6LUx4bvnDQXgD29tYl1RGb+/5nT69UgOuCoRiWXtMsZgZrnAWGBhk12ZQH6D5wWhbU1ff7OZLTGzJSUlJeEqMxDxccb3LxjG7645jQ927GfmvfNZ9NGeoMsSkRgW9mAws27AM8A33b2s6e5mXvKJO7/c/X53z3P3vPT09HCUGbgZIzN47rbJpCQncPUDC3j4nY90E5yIBCKswWBmidSHwuPu/mwzhxQA2Q2eZwHbw1lTJBvSN4XnbpvM2UPSuevF9/nOUyuprNa4g4i0r3BelWTAg8A6d//lEQ57AbgudHXSBKA0lsYXmtOjcyIPXJfHt84dwuwVhXzu9++Sv+dg0GWJSAwJZ4thMnAtMN3MVoR+ZpjZLWZ2S+iYV4DNwEbgAeCrYaynw4iLM75x7mAevD6PbXsO8pn75jP/Q90lLSLtwzpaP3ZeXp4vWbIk6DLazUe7DvCVx5awcWc53zt/GF+ZMoj6xpiISMuZ2VJ3z2vJsbrzOcINTOvK7K9O5oKRGfz01fV87YnlmrZbRMKqRcFgZl3NLC70eIiZfSY0sCztoGtSAvddNZYfzhjGq2uKuOS372jBHxEJm5a2GOYByWaWCbwO3Ag8HK6i5JPMjJunnMRjXzyDXeWHuPCe+fzhrU1U1dQFXZqIRJmWBoO5+0Hgs8C97n4p0HR6C2kHk09O4+Xbz+KswWn89NX1XHjP2yzYvDvoskQkirQ4GMxsInAN8HJoW9im05Cj69+zM/dfl8eD1+dRUV3Llfcv4Ft/XUHJ/kNBlyYiUaClwfBN4AfAbHdfa2aDgLnhK0ta4pzhfXntW2fz9ekn8/KqIqbf/SaPvreF2rqOdaWZiESWVl+uGhqE7tbM9BbtItYuV22pzSXl/Oj5tczfuIsRmd35r0tGMia7Z9BliUiEaPPLVc3sCTPrbmZdqZ8d9QMz++6JFClta1B6Nx774njuu3osJfsPcenv3uHfZq9m38GqoEsTkQ6mpV1Jp4RaCJdQf7dyDvV3NUsEMTNmjurPnG+fzU2TB/Lk4nym3/0Wf1uSrwn5RKTFWhoMiaH7Fi4Bnnf3apqZBVUiQ0pyIv8+8xRe+vqZDEzrynefXsXlf3yPNYWlQZcmIh1AS4Phj8AWoCswz8wGAIGMMUjLDc/ozt++MpGfXzaKTSUHmHnvfL7y2BLWFemrE5EjO+65kswswd3bfW4GDT4fn7LKav48fwt/mr+Z/ZU1XDgyg2+cO5ghfVOCLk1E2kFrBp9bFAxm1gP4MTAltOkt4D/cvd37JhQMJ6b0YDUPzt/MQ+9s4UBVDTNH9ecb5wzm5D7dgi5NRMIoHMHwDLAGeCS06VpgtLt/9rirPE4Khrax90AVD7y9mYff3UJldS0Xj8nk9nMGMzCta9CliUgYhCMYVrj7mGNtaw8Khra1u/wQ98/bzCPvbaG61rl0bCa3Tx9MTmqXoEsTkTYUjmm3K8zszAYfMBmoOJ7iJLKkdkviBzOG8/b3pnPDpFxeXLmd6Xe/yfefWaWV40RiVEtbDKOBR4EeoU17gevdfVUYa2uWWgzhtbOskt+9uYknFm6jzp0LRmZw3cQB5A3opQWCRDqwNu9KavDG3QHcvczMvunuvz7OGo+bgqF9FJVW8MC8j/jb0nz2V9YwrF8K103M5ZKx/enSSfMninQ0YQuGJh+yzd1zjuvFJ0DB0L4OVtXw/IrtPPreVtYVlZGSnMBlp2dx7YQBDErXlUwiHUV7BUO+u2cf14tPgIIhGO7O0q17eeS9rby6uoiaOueswWlcNzGX6cP6EB+nbiaRSKYWg4TVzv2VPLkonycWbmNHWSWZPTtzzYQcrsjLJrVbUtDliUgz2iwYzGw/zc+JZEBnd2/3zmYFQ+Sorq1jzvvFPPLeFhZs3kOnhDguHJnB5/OymDAwlTi1IkQiRru0GIKiYIhMG4r389h7W3lueSH7D9WQ2bMznzs9i8tOy9I9ESIRQMEggamsruUfa3fw9NIC5m/chTuMH9ibz5+exYyRGXRN0hVNIkFQMEhE2L6vgtnLC3l6aQEf7TpAl07xXDAig8tOz+KMgb3V1STSjhQMElHcnWXb9vL00gJeXFlE+aEasnp15nOnZXHZ6Vlk91ZXk0i4KRgkYlVU/aur6Z1N9V1Nk05K5arxOZx3aj86JbR0lhYRaY2ICAYzewiYCex09xHN7J8KPA98FNr0rLv/x7HeV8EQPQr3VfDs0gL+uiSfgr0VpHbtxGV5WVw1LodczfIq0qYiJRimAOXAo0cJhjvcfWZr3lfBEH3q6py3N+7iiYVbmbNuJ7V1zuST61sRnz5FrQiRttCaYAjbJSLuPs/McsP1/hI94uKMs4ekc/aQdIrLKvnbknxmLcrna08sVytCJABhHWMIBcNLR2kxPAMUANupbz2sPcL73AzcDJCTk3P61q1bw1SxRIraOuftD0t4YuE2Xl//r1bE1eMH8KlT+qoVIdJKEdGVFCoklyMHQ3egzt3LzWwG8Bt3H3ys91RXUuwpLqvkqcX5PLk4n8J9FaR168Rlp2dz5bhstSJEWqhDBEMzx24B8tx919GOUzDErto6Z16oFfHGeo1FiLRGRIwxHIuZ9QOK3d3NbDz1q8ntDqoeiXzxcca0oX2YNrQPO0rrxyKeXNx4LOLKcTlat1rkBIXzqqRZwFQgDSgGfgwkArj7H8zsa8CtQA31y4R+293fPdb7qsUgDR0ei5i1aNvHVzQdvi/i06f2JSkhPugSRSJCxHQlhYOCQY5kZ1klf1tawKxF2yjYW0Hvrp247PQsrhyXrUWFJOYpGCSmHb4vYtbCbby2rpjaOidvQC/OGpzOpJNTGZ3VU+MREnMUDCIhh1sRr6wu4v2iMtyhc2I84wb2ZuKgVCadlMqIzB5agU6inoJBpBn7DlaxYPMe3tu0i/c272ZDcTkAKckJnDEwlYkn1QfF0L4pmvlVok6HuCpJpL317NKJ80f04/wR/YD6JUo/DopNu5mzrhiA3l07MXFQKmcNTmP68D70SUkOsmyRdqcWg0hI4b4K3tu0m3dDQVFUWgnAmOyenDu8D+ee0pehfVMwU2tCOh51JYmcIHdn/Y79zHm/mDnrd7Iyfx8AWb06c+7wvpw7vC/jB/bWILZ0GAoGkTa2s6yS19fvZM77xczfuItDNXWkJCVw9tB0zh3el6lD0+nZpVPQZYockYJBJIwqqmqZv3EXc94v5vX1xewqryI+zhiX24tLxmQyc3R/umlta4kwCgaRdlJX56ws2MecdcW8umYHm0vq17aeOSqDK8Zlc1pOL41JSERQMIgE4PDa1n9dnM9Lq4o4WFXLSelduWJcNp89LYu0bklBlygxTMEgErDyQzW8vGo7f12cz7Jt+0iIM84Z3ocrxmUzZXA6CfEatJb2pWAQiSAfFu/nqSX5PLuskN0HqujXPZnLTs/i8rxsclK7BF2exAgFg0gEqqqp4431xTy5OJ95G0qoc5g4KJUrx2dz3qn9SE7UTLASPgoGkQhXVFrB00sK+OuSfAr2VtCzSyKXjs3kqvE5DOmbEnR5EoUUDCIdRF2d8+6m3cxavI1/rt1Bda0zNqcnV43LYeboDLp00mWv0jYUDCId0O7yQ8xeXsisRdvYVHKAbkkJXDS6P1eNz2ZkZg9d9ionRMEg0oG5O0u27uXJRfm8vHo7ldV1nJLRnSvHZ3PxmEx6dE4MukTpgBQMIlGitKKaF1YUMmtRPu8XlZGcGMfMUf25dsIARmf3DLo86UAUDCJRaHVBKbMWb+P55YUcqKplVFYPvjBhAJ8Z3V9XNMkxKRhEotj+ympmLy/ksfe28uHOcnp0TuTyvCyuOWMAuWldgy5PIpSCQSQGuDsLP9rDYwu28o81O6ipc6YMSefaCQOYPqyPliuVRrSCm0gMMDMmDEplwqBUissqeXJRPk8s2sqXH11CZs/OXH1GDleMy9YcTdJqajGIRJHq2jpeX1fMYwu28s7G3STGGzNGZnB5XjYTBqWqFRHD1GIQiVGJ8XGcPyKD80dksHFnOX9ZsJVnlhbw/Irt9OuezMVj+nPpaZkM69c96FIlgqnFIBLlKqtrmbOumOeWF/LmByXU1DnD+qXw2dMy+czoTPr1SA66RGkHGnwWkWbtLj/ES6uKmL28kBX5+zCDySelcenYTM4b0U8rz0UxBYOIHNPmknKeW7Gd55YXsm3PQZIT4zjv1H5cMjaTs05O05oRUSYigsHMHgJmAjvdfUQz+w34DTADOAjc4O7LjvW+CgaRtnV45blnlxXy0qoiSiuqSevWiYtG9+ezY7MYkdld8zRFgUgJhilAOfDoEYJhBvB16oPhDOA37n7Gsd5XwSASPlU1dcz9YCezlxXyxvqdVNXWcVJ6Vz57WhYXj+lPVi8tLNRRRUQwhArJBV46QjD8EXjT3WeFnn8ATHX3oqO9p4JBpH2UHqzmlTVFzF5WyKItewAYP7A3l47NZMbIDE3m18F0lGB4Cfipu88PPX8duNPdP/Fb38xuBm4GyMnJOX3r1q1hq1lEPil/z0FeWLmdZ5cVsKnkAJ3i4zhneB8uHZvJ1KF96JSg8YhI11HuY2iu07LZlHL3+4H7ob7FEM6iROSTsnt34bZpJ/PVqSexprCMZ5cX8OLK7by6Zgc9uyRy4cgMLjs9izHZPTUeEQWCDIYCILvB8yxge0C1iEgLmBkjs3owMqsH/zZjOG9v3MVzywt5ZlkBjy/cxqn9u3PNGQO4eEx/uurS1w4ryG/uBeBrZvYk9YPPpccaXxCRyJEQH8e0oX2YNrQP5YdqeG55IX9ZsJUfzl7N/7yyjkvHZvKFCQMY2k9rWHc04bwqaRYwFUgDioEfA4kA7v6H0OWq9wHnU3+56o3NjS80pcFnkchVf+nrPh5fsJWXVhdRVVNH3oBefGHCAC4Y2Y+kBK0bEZSIGXwOBwWDSMew90AVTy8t4PGFW9my+yC9u3bi83lZXD0+hwGpWjeivSkYRCRi1NU572zaxeMLtvHaumJqQ+tGXHNGDucO76sZX9uJgkFEItKO0kr+ujifWYu2saOskuEZ3fnRzFOYeFJq0KVFPQWDiES0mto6Xl5dxM///gGF+yo4/9R+/HDGcHJSdWd1uLQmGHRXioi0u4T4OC4ek8nr3zmbOz49hHkflnDuL9/ip6+uZ39lddDlxTwFg4gEJjkxnq9NH8zcO6Zy0ej+/OGtTUz7xVv8dfE2aus6Vm9GNFEwiEjg+nZP5u7LR/P8bZMZkNqFO59ZzWfum8/CzbuDLi0mKRhEJGKMzu7J07dM5DdXjmHvgSquuH8BX318Kfl7DgZdWkxRMIhIRDGz0PjDVL517hDmri/hnF++xc//vp7yQzVBlxcTdFWSiES0otIKfv73D5i9vJC0bkncdGYu14wfQI8umva7NXS5qohEnWXb9vKr1zbw9oe76NopnivG5XDTmblaPKiFFAwiErXWbi/lT29/xIsrt+PAhSMzuHnKIEZk9gi6tIimYBCRqLd9XwV/fucjZi3Kp/xQDZNOSuXLUwYxdUi61oRohoJBRGJGWWU1sxZu48/vbGFHWSVD+6bwpbMGcvGYTK0s14CCQURiTlVNHS+u3M4Db29m/Y799O2exA2TBnL1+BwNVKNgEJEY5u7M+3AXD8zbzPyNu+gUH8eUIWnMGJnBuaf0pXtybIZER1nzWUSkzZkZZw9J5+wh6azdXsrsZYW8srqIOet2KiRaSC0GEYl6dXXO8vx9vLK6iFdWF1FUWvlxSFw4KoNzh/clJcpDQsdS6wgAAAirSURBVF1JIiJHcDgkXl5VxKtrQiGREMeUwelcOKpf1IaEgkFEpAXqQ2IvL6/awSuri9hRVh8Sk05K5ZxhfZg2rE/U3ECnYBARaaWGITFnXTHbQhP3DeuXwvRhfThneB/GZPfqsEuRKhhERE6Au7Op5ABz1+/k9fXFLN6yl9o6p1eXRKYO7cP0YX2YMiSdHp07TpeTgkFEpA2VVlQzb0MJc9fvZO4HO9l7sJr4OGNcbi/OGdaXc4b3YVB6t6DLPCoFg4hImNTWOSvy9/L6up28sX4n63fsB+DiMf353vnDyOzZOeAKm6dgEBFpJ4X7Kpi1cBsPvL0ZgC+dNZBbp55Mt6TIuk2sNcGgiURERE5AZs/O3HHeUN64YyoXjOjHb+duYtov3uzQ61YrGERE2kBmz878+sqxzP7qJHJ6169bfeE9b/POxl1Bl9ZqCgYRkTY0NqcXT98ykd9efRrlh2q45k8L+dIji9lUUh50aS0W1mAws/PN7AMz22hm329m/1QzKzWzFaGfH4WzHhGR9mBmXDgqgznfPps7zx/Ggs17OO9X87jrhbXsPVAVdHnHFLbBZzOLBzYAnwIKgMXAVe7+foNjpgJ3uPvMlr6vBp9FpKPZVX6IX722gVmLtpGSnMjt5wzm2gkD2nW9iEgZfB4PbHT3ze5eBTwJXBzGzxMRiUhp3ZL470tH8uo3pjAqqwf/+dL7nPPLN5m1aBtVNXVBl/cJ4QyGTCC/wfOC0LamJprZSjN71cxObe6NzOxmM1tiZktKSkrCUauISNgN7ZfCozeN5883jqNXl0784NnVnP1/c3nk3S1UVtcGXd7HwhkMzU0o0rTfahkwwN1HA/cCzzX3Ru5+v7vnuXteenp6G5cpItJ+zIxpQ/vw/G2TefSm8WT16syPX1jLmT+by/3zNnHgUE3QJYY1GAqA7AbPs4DtDQ9w9zJ3Lw89fgVINLO0MNYkIhIRzIwpQ9L52y2TePLmCQzrl8L/vLKeM3/2Bve98SFlldWB1RbOW/MWA4PNbCBQCFwJXN3wADPrBxS7u5vZeOqDancYaxIRiTgTBqUyYVAqy7bt5bdvbOQX/9zAH+dt5oZJudw0eSC9unZq13rCFgzuXmNmXwP+AcQDD7n7WjO7JbT/D8BlwK1mVgNUAFd6R5ujQ0SkjZyW04sHbxjHmsJSfjt3I/e+sZEH53/EtRMG8MWzBtInJbld6tBcSSIiEWpD8X5+N3cjL6zcTmJ8HN89byhfOmvQcb1XpFyuKiIiJ2BI3xR+feVY3vjOVC4e05+sXu0zc2tkTf8nIiKfkJvWlZ9fNrrdPk8tBhERaUTBICIijSgYRESkEQWDiIg0omAQEZFGFAwiItKIgkFERBpRMIiISCMdbkoMMysBth7ny9OAjrcyd9uJ5fOP5XOH2D5/nXu9Ae7eonULOlwwnAgzW9LSuUKiUSyffyyfO8T2+evcW3/u6koSEZFGFAwiItJIrAXD/UEXELBYPv9YPneI7fPXubdSTI0xiIjIscVai0FERI5BwSAiIo3ETDCY2flm9oGZbTSz7wddT3sysy1mttrMVphZ1K+LamYPmdlOM1vTYFtvM3vNzD4M/dsryBrD5QjnfpeZFYa+/xVmNiPIGsPFzLLNbK6ZrTOztWb2jdD2WPnuj3T+rf7+Y2KMwczigQ3Ap4ACYDFwlbu/H2hh7cTMtgB57h4TN/mY2RSgHHjU3UeEtv0c2OPuPw39YdDL3e8Mss5wOMK53wWUu/svgqwt3MwsA8hw92VmlgIsBS4BbiA2vvsjnf/ltPL7j5UWw3hgo7tvdvcq4Eng4oBrkjBx93nAniabLwYeCT1+hPr/YaLOEc49Jrh7kbsvCz3eD6wDMomd7/5I599qsRIMmUB+g+cFHOd/sA7KgX+a2VIzuznoYgLS192LoP5/IKBPwPW0t6+Z2apQV1NUdqU0ZGa5wFhgITH43Tc5f2jl9x8rwWDNbIv+PrR/mezupwEXALeFuhskdvweOAkYAxQBdwdbTniZWTfgGeCb7l4WdD3trZnzb/X3HyvBUABkN3ieBWwPqJZ25+7bQ//uBGZT37UWa4pDfbCH+2J3BlxPu3H3Ynevdfc64AGi+Ps3s0Tqfyk+7u7PhjbHzHff3Pkfz/cfK8GwGBhsZgPNrBNwJfBCwDW1CzPrGhqIwsy6Ap8G1hz9VVHpBeD60OPrgecDrKVdHf6lGHIpUfr9m5kBDwLr3P2XDXbFxHd/pPM/nu8/Jq5KAghdovVrIB54yN3/O+CS2oWZDaK+lQCQADwR7eduZrOAqdRPOVwM/Bh4DngKyAG2AZ9396gbpD3CuU+lvhvBgS3AVw73uUcTMzsTeBtYDdSFNv+Q+n72WPjuj3T+V9HK7z9mgkFERFomVrqSRESkhRQMIiLSiIJBREQaUTCIiEgjCgYREWlEwSDShJnVNpiJckVbzsZrZrkNZz4ViUQJQRcgEoEq3H1M0EWIBEUtBpEWCq1r8TMzWxT6OTm0fYCZvR6apOx1M8sJbe9rZrPNbGXoZ1LoreLN7IHQnPn/NLPOgZ2USDMUDCKf1LlJV9IVDfaVuft44D7q76Qn9PhRdx8FPA7cE9p+D/CWu48GTgPWhrYPBn7r7qcC+4DPhfl8RFpFdz6LNGFm5e7erZntW4Dp7r45NFnZDndPNbNd1C+QUh3aXuTuaWZWAmS5+6EG75ELvObug0PP7wQS3f2/wn9mIi2jFoNI6/gRHh/pmOYcavC4Fo31SYRRMIi0zhUN/n0v9Phd6mfsBbgGmB96/DpwK9QvL2tm3durSJETob9URD6ps5mtaPD87+5++JLVJDNbSP0fVVeFtt0OPGRm3wVKgBtD278B3G9mX6S+ZXAr9QuliEQ0jTGItFBojCHP3XcFXYtIOKkrSUREGlGLQUREGlGLQUREGlEwiIhIIwoGERFpRMEgIiKNKBhERKSR/w+RgZmDF6wFIwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist4.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: полученные результаты мне нравятся больше всего, так как значение потери равно 0.201 - это лучший полученный результат. Мне показалось, что пунктуация в тексте приобрела новый уровень. Количество русских слов увеличилось, но качество самого текста все же не на высоте, он все еще напоминает бессмысленный старославянский, но это связано с посимвольным предсказанием, если бы использовались целые слова, текст содержал бы в себе больше ценности."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
